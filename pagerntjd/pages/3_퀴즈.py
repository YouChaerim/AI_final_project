import streamlit as st
import configparser
import openai
import json
import os

# --- ì´ì „ì— ì‚¬ìš©í•˜ì…¨ë˜ CSS ìŠ¤íƒ€ì¼ ---
custom_css = """
<style>
/* ì „ì²´ í°íŠ¸ ë° ë°°ê²½ */
body, .css-18e3th9 {
    font-family: 'Noto Sans KR', sans-serif;
    background-color: #fff;
    color: #333;
}

/* ìµœëŒ€ ë„ˆë¹„ ë°•ìŠ¤ ì¤‘ì•™ ì •ë ¬ */
.main .block-container {
    max-width: 960px;
    padding-top: 20px;
    padding-bottom: 40px;
}

/* ì‚¬ì´ë“œë°” ìˆ¨ê¸°ê¸° */
[data-testid="stSidebar"] {
    display: none;
}
button[title="ì‚¬ì´ë“œë°” í† ê¸€"] {
    display: none;
}

/* ì˜¤ë¥¸ìª½ ìƒë‹¨ ë©”ë‰´ ìˆ¨ê¸°ê¸° (Deploy ë²„íŠ¼ í¬í•¨) */
header > div:first-child {
    display: none !important;
}

/* í˜ì´ì§€ ì¢Œì¸¡ ì—¬ë°± ìµœì†Œí™” */
.main > div:first-child {
    padding-left: 0rem;
}

/* ìƒë‹¨ ë„¤ë¹„ê²Œì´ì…˜ ë°” ìŠ¤íƒ€ì¼ */
.navbar {
    display: flex;
    align-items: center;
    gap: 24px;
    padding: 12px 20px;
    border-bottom: 1px solid #eee;
    font-weight: 600;
    font-size: 16px;
    font-family: 'Noto Sans KR', sans-serif;
    margin-bottom: 40px;
}
.navbar .logo {
    font-weight: 700;
    font-size: 26px;
    color: #FF6600;
    user-select: none;
}
.navbar a {
    color: #222;
    text-decoration: none;
    cursor: pointer;
    transition: color 0.2s ease;
}
.navbar a:hover, .navbar a.active {
    color: #FF6600;
}

/* í€´ì¦ˆ ë°•ìŠ¤ */
.quiz-container {
    width: 520px;
    margin: 0 auto 40px auto;
    border: 2px solid #FF6600;
    border-radius: 8px;
    overflow: hidden;
    box-shadow: 0 4px 12px rgb(255 102 0 / 0.2);
}

/* í—¤ë” ë°” */
.quiz-header {
    background: linear-gradient(90deg, #FF7F00, #E65C00);
    color: white;
    text-align: center;
    font-size: 28px;
    font-weight: 700;
    padding: 16px 0;
    user-select: none;
}

/* ë¬¸ì œ ë²ˆí˜¸ ë° ì§ˆë¬¸ */
.quiz-question {
    text-align: center;
    font-size: 18px;
    padding: 20px 16px 8px;
    user-select: none;
}

/* ê°ê´€ì‹ ì„ íƒì§€ ê·¸ë¦¬ë“œ */
.options-grid {
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 14px 18px;
    padding: 0 20px 20px;
}

/* ê° ì„ íƒì§€ ë°•ìŠ¤ */
.option-btn {
    border: 1.5px solid #eee;
    border-radius: 12px;
    background: #fefefe;
    padding: 14px 12px;
    font-weight: 600;
    cursor: pointer;
    transition: background-color 0.3s ease, border-color 0.3s ease;
    user-select: none;
    display: flex;
    align-items: center;
    gap: 12px;
}
.option-btn:hover {
    background-color: #fff3e6;
    border-color: #ff8c33;
}
.option-label {
    color: #FF6600;
    font-weight: 700;
    font-size: 18px;
    user-select: none;
}

/* ë‹¤ìŒ ë²„íŠ¼ */
.next-btn-container {
    text-align: center;
    padding: 0 0 24px;
}
.next-btn {
    background-color: #FF6600;
    border: none;
    border-radius: 12px;
    color: white;
    font-size: 20px;
    font-weight: 700;
    padding: 12px 64px;
    cursor: pointer;
    transition: background-color 0.25s ease;
    user-select: none;
}
.next-btn:hover {
    background-color: #cc5200;
}

/* ê¸°íƒ€ í¼ ìš”ì†Œ ìŠ¤íƒ€ì¼ */
.stRadio > div {
    margin-left: 0 !important;
}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)

# --- ë„¤ë¹„ê²Œì´ì…˜ ë°” (ê³µì§€ ì‚­ì œë¨) ---
nav_html = """
<div class="navbar">
    <div class="logo">ë”¸ê¹ê³µ</div>
    <a href="/mainpage">ë©”ì¸í˜ì´ì§€</a>
    <a href="/ê³µë¶€_ì‹œì‘" class="active">ê³µë¶€ ì‹œì‘</a>
    <a href="/í•„ê¸°">í•„ê¸°</a>
    <a href="/ì €ì¥í´ë”">ì €ì¥í´ë”</a>
    <a href="/í€´ì¦ˆ">í€´ì¦ˆ</a>
    <a href="/ë¦¬í¬íŠ¸">ë¦¬í¬íŠ¸(í”¼ë“œë°±)</a>
</div>
"""
st.markdown(nav_html, unsafe_allow_html=True)

# --- config.ini ë¡œë“œ ë° OpenAI ì´ˆê¸°í™” ---
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
CONFIG_PATH = os.path.join(BASE_DIR, "config.ini")

config = configparser.ConfigParser()
try:
    with open(CONFIG_PATH, encoding='utf-8') as f:
        config.read_file(f)
except Exception as e:
    st.error(f"âŒ config.ini íŒŒì¼ ë¬¸ì œ: {e}")
    st.stop()

if not config.has_section("openai"):
    st.error(f"âŒ config.iniì— [openai] ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤!")
    st.stop()

api_key = config.get("openai", "api_key")
client = openai.OpenAI(api_key=api_key)

st.set_page_config(page_title="GPT í€´ì¦ˆ ìƒì„±ê¸°", layout="centered")

st.markdown('<div class="quiz-container">', unsafe_allow_html=True)
st.markdown('<div class="quiz-header">í€´ì¦ˆ í’€ê¸°</div>', unsafe_allow_html=True)

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
for key in ["quiz_data", "user_answers", "confirmed_answers", "wrong_indices", "chat_logs", "summary_log", "graded", "current_question"]:
    if key not in st.session_state:
        st.session_state[key] = [] if "data" in key else (False if key in ["graded"] else 0 if key=="current_question" else {})

# --- GPT í€´ì¦ˆ ìƒì„± í•¨ìˆ˜ (ì—„ê²© JSON ë°˜í™˜) ---
def generate_quiz(content):
    system_prompt = """
ë„ˆëŠ” ë˜‘ë˜‘í•œ ì„ ìƒë‹˜ì´ì•¼. í•™ìŠµ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì–‘í•œ í€´ì¦ˆë¥¼ JSON ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì¤˜.
- ì´ 8ë¬¸ì œ, ìœ í˜•ì€ OX, ê°ê´€ì‹, ì£¼ê´€ì‹, ë¹ˆì¹¸ ì¤‘ ëœë¤í•˜ê²Œ êµ¬ì„±.
- ë¬¸ì œ ìœ í˜•ì€ ê· ë“±í•˜ì§€ ì•Šì•„ë„ ë˜ê³  ììœ ë¡­ê²Œ êµ¬ì„± ê°€ëŠ¥.
- ê° ë¬¸ì œëŠ” ë°˜ë“œì‹œ ì•„ë˜ í•­ëª© í¬í•¨:
  - type: 'OX' | 'ê°ê´€ì‹' | 'ì£¼ê´€ì‹' | 'ë¹ˆì¹¸'
  - question: ì§ˆë¬¸ ë‚´ìš© (ë¬¸ìì—´)
  - options: (ê°ê´€ì‹ ë˜ëŠ” OX ë¬¸ì œì—ë§Œ) ì„ íƒì§€ ë¦¬ìŠ¤íŠ¸ (ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸)
  - answer: ì •ë‹µ (ë¬¸ìì—´ ë˜ëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸)
  - explanation: í•´ì„¤ (ì™œ ì •ë‹µì¸ì§€ ì„¤ëª…, ë¬¸ìì—´)
  - example: ì˜ˆì‹œ ë˜ëŠ” ë°°ê²½ ì„¤ëª… (ì„ íƒì‚¬í•­, ë¬¸ìì—´)
- JSON ë°°ì—´ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…, í…ìŠ¤íŠ¸, ì£¼ì„ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆ.
- ë°˜ë“œì‹œ ì •í™•í•œ JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ê³ , ì—¬ë°±, ì¤„ë°”ê¿ˆë„ í¬í•¨í•´ë„ ê´œì°®ìŒ.
"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": content}
            ],
            temperature=0.7
        )
        raw_text = response.choices[0].message.content.strip()
        quiz_json = json.loads(raw_text)
        return quiz_json
    except json.JSONDecodeError as e:
        st.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        st.text_area("ğŸ“ GPT ì‘ë‹µ ì›ë¬¸ (ë””ë²„ê¹…ìš©)", raw_text, height=300)
        return []
    except Exception as e:
        st.error(f"âŒ í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        return []

# --- ìš”ì•½, ì˜¤ë‹µ í”¼ë“œë°±, ë¬¸ì œ í‘œì‹œ, ì±„ì , ëŒ€í™” í•¨ìˆ˜ëŠ” ì´ì „ ì½”ë“œì™€ ë™ì¼ ---

def summarize_content(content):
    try:
        system = "ì•„ë˜ ë‚´ìš©ì„ 3~5ì¤„ë¡œ ìš”ì•½í•´ì¤˜."
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": content}
            ]
        )
        return response.choices[0].message.content.strip()
    except:
        return "ìš”ì•½ ì‹¤íŒ¨"

def ask_gpt_about_wrong(problem, user_answer):
    prompt = f"""ë¬¸ì œ: {problem['question']}
ì •ë‹µ: {problem['answer']}
ë‚´ê°€ ì‘ì„±í•œ ì˜¤ë‹µ: {user_answer}
ì™œ í‹€ë ¸ëŠ”ì§€ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜."""
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ì„ ìƒë‹˜ì´ì•¼."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

def summarize_answer(answer):
    try:
        system = "ì•„ë˜ ë‚´ìš©ì„ ìµœëŒ€ 2ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜."
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system},
                {"role": "user", "content": answer}
            ]
        )
        return response.choices[0].message.content.strip()
    except:
        return "ìš”ì•½ ì‹¤íŒ¨"

def show_current_question():
    idx = st.session_state.current_question
    quiz = st.session_state.quiz_data[idx]
    total = len(st.session_state.quiz_data)

    st.markdown(f'<div class="quiz-question">{idx+1} / {total}<br>{quiz["question"]}</div>', unsafe_allow_html=True)

    if quiz["type"] in ["ê°ê´€ì‹", "OX"]:
        options = quiz.get("options", [])
        selected = st.radio("", options, key="current_answer")
    else:
        selected = st.text_input("ì •ë‹µ ì…ë ¥", key="current_answer")

    if st.button("ë‹¤ìŒ"):
        st.session_state.user_answers[idx] = selected
        st.session_state.confirmed_answers[idx] = True
        if idx + 1 < total:
            st.session_state.current_question += 1
        else:
            st.session_state.graded = True

def grade_quiz():
    st.subheader("ğŸ¯ ì±„ì  ê²°ê³¼")
    wrongs = []
    for i, quiz in enumerate(st.session_state.quiz_data):
        user = str(st.session_state.user_answers.get(i, "")).strip()
        answer = quiz["answer"]
        correct = user in answer if isinstance(answer, list) else user == str(answer).strip()

        st.markdown(f"**ë¬¸ì œ {i + 1}: {'âœ… ì •ë‹µ' if correct else 'âŒ ì˜¤ë‹µ'}**")
        st.markdown(f"- ì§ˆë¬¸: {quiz['question']}")
        if quiz["type"] in ["ê°ê´€ì‹", "OX"]:
            st.markdown(f"- ì„ íƒì§€: {', '.join(quiz.get('options', []))}")
        st.markdown(f"- ì •ë‹µ: {answer}")
        st.markdown(f"- í•´ì„¤: {quiz.get('explanation', 'ì—†ìŒ')}")
        st.markdown(f"- ì˜ˆì‹œ: {quiz.get('example', 'ì—†ìŒ')}")
        st.markdown("---")

        if not correct:
            wrongs.append(i)
    st.session_state.wrong_indices = wrongs

def wrong_gpt_chat():
    for i in st.session_state.wrong_indices:
        quiz = st.session_state.quiz_data[i]
        user_answer = st.session_state.user_answers[i]
        question_key = quiz["question"]

        if question_key not in st.session_state.chat_logs:
            reply = ask_gpt_about_wrong(quiz, user_answer)
            st.session_state.chat_logs[question_key] = [{"role": "assistant", "content": reply}]
            st.session_state[f"last_reply_{i}"] = reply

        with st.expander(f"ğŸ’¬ GPTì—ê²Œ ë¬¸ì œ {i+1} ì§ˆë¬¸í•˜ê¸°", expanded=True):
            st.markdown(f"ğŸ§  GPT ë‹µë³€: {st.session_state[f'last_reply_{i}']}")
            st.markdown(f"ğŸ“Œ ìš”ì•½: {summarize_answer(st.session_state[f'last_reply_{i}'])}")

            with st.form(key=f"form_followup_{i}"):
                key_followup = f"followup_{i}_text"
                user_followup = st.text_input("ì¶”ê°€ ì§ˆë¬¸ ì…ë ¥", key=key_followup)
                submitted = st.form_submit_button("ì§ˆë¬¸ ë³´ë‚´ê¸°")

                if submitted and user_followup.strip():
                    chat = st.session_state.chat_logs[question_key]
                    chat.append({"role": "user", "content": user_followup})

                    response = client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "system", "content": "ì¹œì ˆí•œ í”¼ë“œë°±ì„ ì œê³µí•´ì¤˜."}] + chat
                    )
                    reply = response.choices[0].message.content.strip()
                    chat.append({"role": "assistant", "content": reply})

                    st.session_state.chat_logs[question_key] = chat
                    st.session_state[f"last_reply_{i}"] = reply

            with st.expander("ğŸ“œ ì „ì²´ ëŒ€í™” ë³´ê¸°", expanded=False):
                for msg in st.session_state.chat_logs[question_key]:
                    who = "ğŸ™‹ ì§ˆë¬¸" if msg["role"] == "user" else "ğŸ§  ë‹µë³€"
                    st.markdown(f"{who}: {msg['content']}")

# --- í€´ì¦ˆ ìƒì„± í¼ ---
with st.form(key="quiz_form"):
    st.markdown('<div class="form-card">', unsafe_allow_html=True)
    quiz_type = st.selectbox("ë¬¸ì œ ìœ í˜•", ["ëª¨ë“  ìœ í˜•", "OX", "ê°ê´€ì‹", "ì£¼ê´€ì‹", "ë¹ˆì¹¸"])
    quiz_count = st.slider("ì¶œì œí•  í€´ì¦ˆ ê°œìˆ˜", 1, 10, 8)  # ìµœì†Œê°’ 1
    content = st.text_area("âœï¸ í•™ìŠµ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”", height=200)
    st.markdown('</div>', unsafe_allow_html=True)

    submit = st.form_submit_button("ğŸ§  í€´ì¦ˆ ìƒì„±í•˜ê¸°")

if submit:
    if not content.strip():
        st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    elif len(content.strip()) < 5:
        st.error("âŒ í€´ì¦ˆë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        with st.spinner("GPTê°€ í€´ì¦ˆì™€ ìš”ì•½ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            st.session_state.summary_log = summarize_content(content)
            quiz = generate_quiz(content)
            if quiz:
                st.session_state.quiz_data = quiz[:quiz_count]
                st.session_state.user_answers = {}
                st.session_state.confirmed_answers = {}
                st.session_state.wrong_indices = []
                st.session_state.chat_logs = {}
                st.session_state.graded = False
                st.session_state.current_question = 0

# --- í˜„ì¬ ë¬¸ì œ ë³´ì—¬ì£¼ê¸° ---
if st.session_state.quiz_data and not st.session_state.graded:
    show_current_question()

# --- ì±„ì  ë° ì˜¤ë‹µ í”¼ë“œë°± ë³´ì—¬ì£¼ê¸° ---
if st.session_state.graded:
    grade_quiz()
    wrong_gpt_chat()

# --- í•™ìŠµ ìš”ì•½ ë³´ì—¬ì£¼ê¸° ---
if st.session_state.get("summary_log"):
    st.info(f"ğŸ“š í•™ìŠµ ìš”ì•½:\n\n{st.session_state.summary_log}")
