
# app.py
# -*- coding: utf-8 -*- (ìœ ë‹ˆì½”ë“œë¡œ ìˆ˜ì • 2025/07/25)
import io, os, re, gc, json, random
import numpy as np
import streamlit as st
import cv2
from PIL import Image
from dotenv import load_dotenv
from openai import OpenAI
from PyPDF2 import PdfReader
from pdf2image import convert_from_bytes
from pdf2image.exceptions import PDFInfoNotInstalledError

# =========================
# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env)
# =========================
load_dotenv(dotenv_path="C:/Users/user/Desktop/main_project/AI_final_project/.env")
from dotenv import load_dotenv

# ---- optional: PaddleOCR
try:
    from paddleocr import PaddleOCR
except Exception:
    PaddleOCR = None

st.set_page_config(page_title="PDF ìš”ì•½ & í€´ì¦ˆ", layout="wide", initial_sidebar_state="collapsed")
load_dotenv(dotenv_path="C:/Users/user/Desktop/main_project/.env")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
POPPLER_PATH   = os.getenv("POPPLER_PATH")  # ì˜ˆ) C:/Users/user/anaconda3/envs/final/Library/bin

# =========================
# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • & CSS
# =========================
st.set_page_config(page_title="ğŸ“„ OCR + GPT ìš”ì•½/í€´ì¦ˆ ìƒì„±ê¸°",
                   layout="centered",
                   initial_sidebar_state="collapsed")

# ---- THEME (CSS ì£¼ì… ì „ í•„ìˆ˜) ----
u = st.session_state.get("user_data") or {}
dark = bool(u.get("dark_mode", False))

if dark:
    bg_color  = "#1C1C1E"
    font_color = "#F2F2F2"
    card_bg   = "#2C2C2E"
    nav_bg    = "#2C2C2E"
    nav_link  = "#F2F2F2"
else:
    bg_color  = "#FAFAFA"
    font_color = "#333"
    card_bg   = "white"
    nav_bg    = "rgba(255,255,255,0.9)"
    nav_link  = "#000"


st.markdown(f"""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@400;600;800;900&display=swap');
html, body {{ background-color:{bg_color}; color:{font_color}; font-family:'Noto Sans KR', sans-serif; zoom:1.10; margin:0; }}
.stApp {{ background-color:{bg_color}; }}

.block-container {{ padding-top:0 !important; }}
a {{ text-decoration:none !important; color:{font_color}; }}
header, [data-testid="stSidebar"], [data-testid="stToolbar"] {{ display:none !important; }}
::selection {{ background:#FF9330; color:white; }}


.container {{ max-width:1200px; margin:auto; padding:8px 40px 40px !important; }}

.top-nav {{ display:flex; justify-content:space-between; align-items:center; padding:12px 0; margin-top:40px !important; background-color:{nav_bg}; box-shadow:0 2px 4px rgba(0,0,0,0.05); }}
.nav-left {{ display:flex; align-items:center; gap:60px; }}
.top-nav .nav-left > div:first-child a {{ color:#000 !important; font-size:28px; font-weight:bold; }}
.nav-menu {{ display:flex; gap:36px; font-size:18px; font-weight:600; }}
.nav-menu div a {{ color:{nav_link} !important; transition:.2s; }}
.nav-menu div:hover a {{ color:#FF9330 !important; }}
.nav-menu .active a {{ color:#FF8A00 !important; }}
.profile-group {{ display:flex; gap:16px; align-items:center; margin-right:12px; }}
.profile-icon {{ width:36px; height:36px; border-radius:50%; background:linear-gradient(135deg,#DDEFFF,#F8FBFF);
  overflow:hidden; display:flex; align-items:center; justify-content:center; box-shadow:0 1px 2px rgba(0,0,0,0.06); }}
.profile-icon img {{ width:100%; height:100%; object-fit:contain; }}


/* ìƒë‹¨ ì„¹ì…˜ ë°°ë„ˆ(í€´ì¦ˆ ìƒì„±ê¸°/ PDFìš”ì•½ ê³µí†µ) */
.section{{ width:100%; background:{card_bg}; border:1px solid #F2D4B6; border-radius:14px; box-shadow:0 6px 18px rgba(17,24,39,0.06); overflow:hidden; margin:10px 0 22px 0; }}
.section-header{{ background:linear-gradient(90deg,#FF7A00,#FFA74D); color:#fff; text-align:center; font-weight:900; font-size:40px; padding:18px 0; }}
.section-body{{ padding:18px; }}

/* PDF ì¹´ë“œ */
.capture-card {{ width:100%; background:#fff; border:1px solid #F1E6D8; border-radius:18px;
  box-shadow:0 18px 48px rgba(17,24,39,.06); padding:26px 26px 22px; margin-top:6px; }}
.cam-wrap {{ display:flex; align-items:flex-start; gap:32px; }}

.cam-square {{ width:340px; height:340px; border-radius:18px; background:linear-gradient(180deg,#F6F9FF 0%,#EEF2F7 100%);
  border:1px solid #E9EEF6; box-shadow:0 1px 0 #FFFFFF inset, 0 10px 26px rgba(17,24,39,.06); display:flex; align-items:center; justify-content:center; }}
.cam-square .inner{{ display:flex; flex-direction:column; align-items:center; gap:16px; color:#8A94A6; }}
.cam-square .label{{ font-weight:800; font-size:18px; color:#6B7280; }}

.right-col .title {{ font-size:44px; font-weight:900; margin-top:6px; margin-bottom:8px; }}
.right-col .desc  {{ font-size:20px; color:#4B5563; margin-bottom:16px; }}
.btn-row {{ display:flex; gap:12px; align-items:center; margin:6px 0 8px; }}
div[data-testid="stFileUploader"]{{ width:210px; }}
div[data-testid="stFileUploader"] section[data-testid="stFileUploaderDropzone"],
div[data-testid="stFileUploader"] div[data-testid="stFileUploaderDropzone"]{{ padding:0 !important; border:none !important; height:52px; width:210px; border-radius:12px;
  background:linear-gradient(90deg,#FF8A00,#FF7A00); box-shadow:0 8px 18px rgba(255,138,0,.18); cursor:pointer; }}
div[data-testid="stFileUploader"] section[data-testid="stFileUploaderDropzone"] *,
div[data-testid="stFileUploader"] div[data-testid="stFileUploaderDropzone"] * {{ display:none !important; }}
div[data-testid="stFileUploader"] section[data-testid="stFileUploaderDropzone"]::after,
div[data-testid="stFileUploader"] div[data-testid="stFileUploaderDropzone"]::after{{ content:"íŒŒì¼ ì—…ë¡œë“œ"; display:flex; align-items:center; justify-content:center; height:52px; width:210px; color:#fff; font-weight:900; letter-spacing:.2px; }}
div[data-testid="stFileUploader"] label {{ display:none !important; }}
.ghost-btn .stButton>button{{ height:52px; padding:0 22px; background:#fff; color:#334155; border:1.5px solid #E5E7EB; border-radius:12px; font-weight:900; }}
.ghost-btn .stButton>button:hover{{ border-color:#FFB066; color:#FF7A00; }}

.small-note{{ color:#9AA3AF; margin-top:8px; }}

/* í€´ì¦ˆ í”Œë ˆì´ì–´ */
.quiz-shell{{ width:100%; background:#fff; border:2px solid #FFA65A; border-radius:10px; box-shadow:0 8px 24px rgba(17,24,39,.08); overflow:hidden; }}
.quiz-header{{ background:linear-gradient(90deg,#FF7A00,#FFA74D); color:#fff; text-align:center; font-weight:900; font-size:36px; padding:14px 0; border-bottom:1px solid #EFD0B2; }}
.quiz-body{{ padding:22px 24px 26px; }}
.quiz-meta{{ text-align:center; color:#111827; font-weight:800; margin-bottom:8px; }}
.quiz-question{{ text-align:center; font-size:22px; margin:6px 0 18px; }}
.opt2 .stButton>button{{ width:100%; border:1.5px solid #EFEFEF; background:#fff; border-radius:12px; padding:14px 16px; text-align:left; font-weight:700; box-shadow:0 1px 2px rgba(0,0,0,0.03); }}
.opt2 .stButton>button:hover{{ border-color:#FFD2A8; }}
.opt2.selected .stButton>button{{ border-color:#FFB066; box-shadow:0 0 0 2px rgba(255,138,0,.15) inset; }}
.action-row{{ display:flex; justify-content:center; gap:12px; margin-top:10px; }}
.action-row .stButton>button{{ height:56px; padding:0 36px; border-radius:12px; font-weight:900; border:0; }}
.next-btn .stButton>button{{ background:#FF8A00; color:#fff; }}
.prev-btn .stButton>button{{ background:#fff; color:#334155; border:1.5px solid #E5E7EB; }}
.score-pill{{ display:inline-block; padding:6px 12px; background:#FFF7ED; border:1px solid #FCD9BD; border-radius:999px; font-weight:800; color:#9A3412; }}
.result-good{{ color:#0E7C3F; font-weight:900; }}
.result-bad{{ color:#B91C1C; font-weight:900; }}
</style>
""", unsafe_allow_html=True)

# =========================
# OpenAI í´ë¼ì´ì–¸íŠ¸ ìºì‹±
# =========================
# í—¤ë”(ê·¸ëŒ€ë¡œ)
st.markdown(f"""
<div class="top-nav">
  <div class="nav-left">
    <div style="font-size:28px; font-weight:bold;">
      <a href="/" target="_self">ğŸ¾ ë”¸ê¹ê³µ</a>
    </div>
    <div class="nav-menu">
      <div><a href="/"             target="_self">ë©”ì¸í˜ì´ì§€</a></div>
      <div><a href="/main"         target="_self">ê³µë¶€ ì‹œì‘</a></div>
      <div class="active"><a href="/ocr_paddle"   target="_self">PDF ìš”ì•½</a></div>
      <div><a href="/folder_page"  target="_self">ì €ì¥í´ë”</a></div>
      <div><a href="/quiz"         target="_self">í€´ì¦ˆ</a></div>
      <div><a href="/report"       target="_self">ë¦¬í¬íŠ¸</a></div>
      <div><a href="/ranking"      target="_self">ë­í‚¹</a></div>
    </div>
  </div>
  <div class="profile-group">
    <div class="profile-icon" title="ë‚´ ìºë¦­í„°">
      <img src="{avatar_uri}" alt="avatar"/>
    </div>
  </div>
</div>
""", unsafe_allow_html=True)

# ========= OpenAI / OCR helpers =========
@st.cache_resource
def get_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("âŒ .env íŒŒì¼ì—ì„œ OpenAI API í‚¤(OPENAI_API_KEY)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    return OpenAI(api_key=api_key)

client = get_openai_client()
MODEL_SUMMARY = "gpt-4o-mini"   # í•„ìš”ì‹œ êµì²´

# =========================
# OCR (PaddleOCR) ìºì‹±
# =========================
@st.cache_resource
def get_ocr():
    from paddleocr import PaddleOCR
    for kwargs in [
        dict(lang="korean", use_angle_cls=True),
        dict(lang="korean"),
        dict(),  # ìµœí›„ì˜ ìˆ˜ë‹¨
    ]:
        try:
            return PaddleOCR(**kwargs)
        except TypeError:
            continue
    st.error("âŒ PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: ë²„ì „ í˜¸í™˜ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.")
    st.stop()

# =========================
# ê³µí†µ ìœ í‹¸
# =========================
def _prep_im_for_ocr(pil_img: Image.Image, max_side: int = 2000) -> np.ndarray:
    """PIL -> BGR, ê¸´ ë³€ max_sideë¡œ ì¶•ì†Œ."""
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    arr = np.array(pil_img)                 # RGB
    arr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)
    h, w = arr.shape[:2]
    m = max(h, w)
    if m > max_side:
        scale = max_side / float(m)
        arr = cv2.resize(arr, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_LINEAR)
    return np.ascontiguousarray(arr)

def _group_runs(pages):
    """ì˜ˆ: [3,4,5, 9,10] -> [(3,5), (9,10)] ì—°ì† êµ¬ê°„ ë¬¶ê¸°"""
    if not pages: return []
    runs, s, e = [], pages[0], pages[0]
    for p in pages[1:]:
        if p == e + 1:
            e = p
        else:
            runs.append((s, e))
            s = e = p
    runs.append((s, e))
    return runs

@st.cache_data(show_spinner=False)
def pdf_pages_to_texts(
    pdf_bytes: bytes,
    *,
    dpi: int = 120,
    min_chars_for_pdftext: int = 10,
):
    """
    ìë™ ì •ì±…:
      1) ë‚´ì¥ í…ìŠ¤íŠ¸ ìš°ì„ 
      2) ì»¤ë²„ë¦¬ì§€ ë¹„ìœ¨ë¡œ ê²°ì •
         - >=70%: í…ìŠ¤íŠ¸ë§Œ
         - 30~70%: í•˜ì´ë¸Œë¦¬ë“œ(ë¶€ì¡± í˜ì´ì§€ë§Œ OCR)
         - <30% : ì „ì²´ OCR
    return: [(page_no, text), ...], total_pages
    """
    # 1) ë‚´ì¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    try:
        reader = PdfReader(io.BytesIO(pdf_bytes))
        base_pages = [(i+1, (p.extract_text() or "")) for i, p in enumerate(reader.pages)]
    except Exception:
        base_pages = []
    total_pages = len(base_pages)

    # ë‚´ì¥ í…ìŠ¤íŠ¸ ì „ë¬´ â†’ ì „ì²´ OCR
    if total_pages == 0:
        try:
            kw = {"dpi": dpi}
            if POPPLER_PATH: kw["poppler_path"] = POPPLER_PATH
            images = convert_from_bytes(pdf_bytes, **kw)
        except PDFInfoNotInstalledError:
            st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: OCR ì‚¬ìš© ë¶ˆê°€")
            return [], 0
        ocr = get_ocr()
        out, prog = [], st.progress(0.0, text=f"OCR ì „ì²´ ì§„í–‰ ì¤‘â€¦ ({len(images)}p, DPI={dpi})")
        for i, img in enumerate(images, start=1):
            arr = _prep_im_for_ocr(img, max_side=2000)
            res = ocr.ocr(arr)
            txt = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            out.append((i, txt))
            prog.progress(i/len(images))
            del img
        prog.empty()
        st.caption("ëª¨ë“œ: ì „ì²´ OCR (ë‚´ì¥ í…ìŠ¤íŠ¸ ì—†ìŒ)")
        return out, len(images)

    # 2) ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
    lengths = [len((t or "").strip()) for _, t in base_pages]
    text_pages = sum(1 for L in lengths if L >= min_chars_for_pdftext)
    coverage = text_pages / max(1, total_pages)

    if coverage >= 0.70:
        st.caption(f"ëª¨ë“œ: í…ìŠ¤íŠ¸ë§Œ (ì»¤ë²„ë¦¬ì§€ {coverage:.0%})")
        return base_pages, total_pages

    if coverage < 0.30:
        # ì „ì²´ OCR
        try:
            kw = {"dpi": dpi}
            if POPPLER_PATH: kw["poppler_path"] = POPPLER_PATH
            images = convert_from_bytes(pdf_bytes, **kw)
        except PDFInfoNotInstalledError:
            st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: ì „ì²´ OCR ë¶ˆê°€ â†’ ë‚´ì¥ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©")
            st.caption(f"ëª¨ë“œ: í…ìŠ¤íŠ¸ë§Œ (ì»¤ë²„ë¦¬ì§€ {coverage:.0%}, OCR ë¶ˆê°€)")
            return base_pages, total_pages
        ocr = get_ocr()
        out, prog = [], st.progress(0.0, text=f"OCR ì „ì²´ ì§„í–‰ ì¤‘â€¦ ({len(images)}p, DPI={dpi})")
        for i, img in enumerate(images, start=1):
            arr = _prep_im_for_ocr(img, max_side=2000)
            res = ocr.ocr(arr)
            txt = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            out.append((i, txt))
            prog.progress(i/len(images))
            del img
        prog.empty()
        st.caption(f"ëª¨ë“œ: ì „ì²´ OCR (ì»¤ë²„ë¦¬ì§€ {coverage:.0%})")
        return out, len(images)

    # 3) í•˜ì´ë¸Œë¦¬ë“œ: ë¶€ì¡± í˜ì´ì§€ë§Œ OCR
    need_pages = [pg for (pg, t) in base_pages if len((t or "").strip()) < min_chars_for_pdftext]
    runs = _group_runs(need_pages)
    page_to_text = {pg: (t or "") for pg, t in base_pages}
    ocr = get_ocr()
    done = 0
    prog = st.progress(0.0, text=f"í•˜ì´ë¸Œë¦¬ë“œ: ë¶€ì¡± í˜ì´ì§€ë§Œ OCR ì¤‘â€¦ (ì´ {len(need_pages)}p, DPI={dpi})")
    for s, e in runs:
        try:
            kw = {"dpi": dpi, "first_page": s, "last_page": e}
            if POPPLER_PATH: kw["poppler_path"] = POPPLER_PATH
            imgs = convert_from_bytes(pdf_bytes, **kw)
        except PDFInfoNotInstalledError:
            st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: OCR ë³´ì¶© ìƒëµ â†’ ë‚´ì¥ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©")
            break
        for idx, pg in enumerate(range(s, e+1)):
            arr = _prep_im_for_ocr(imgs[idx], max_side=2000)
            res = ocr.ocr(arr)
            t2 = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            page_to_text[pg] = t2
            done += 1
            prog.progress(done / max(1, len(need_pages)))
        del imgs
    prog.empty()
    out = [(pg, page_to_text.get(pg, "")) for pg, _ in base_pages]
    st.caption(f"ëª¨ë“œ: í•˜ì´ë¸Œë¦¬ë“œ (ì»¤ë²„ë¦¬ì§€ {coverage:.0%}, OCR {len(need_pages)}p)")
    return out, total_pages

# =========================
# í…ìŠ¤íŠ¸ ë¶„í• /ìš”ì•½ ìœ í‹¸
# =========================
def split_text_by_chars(s: str, max_chars: int):
    paras = re.split(r"\n{2,}", s)
    chunks, buff = [], ""
    for p in paras:
        p = p.strip()
        if not p: continue
        if len(buff) + len(p) + 2 <= max_chars:
            buff = (buff + "\n\n" + p).strip()
        else:
            if buff: chunks.append(buff)
            if len(p) > max_chars:
                sents = re.split(r"(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+", p)
                cur = ""
                for sent in sents:
                    if len(cur) + len(sent) + 1 <= max_chars:
                        cur = (cur + " " + sent).strip()
                    else:
                        if cur: chunks.append(cur)
                        cur = sent
                if cur: chunks.append(cur)
            else:
                buff = p
    if buff: chunks.append(buff)
    return chunks

def gpt_chat(messages, model=MODEL_SUMMARY, temperature=0.2, max_tokens=None):
        return "\n".join([page.extract_text() or "" for page in reader.pages])
    except:
        return ""

def safe_load_json5(text):
    try:
        return json5.loads(text)
    except Exception as e:
        st.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        st.code(text)
        return []

def generate_quiz(content, quiz_count=8, allowed_types=None):
    type_hint = ""
    if allowed_types:
        type_hint = f"ë°˜ë“œì‹œ ë‹¤ìŒ ìœ í˜•ë§Œ ì‚¬ìš©: {', '.join(allowed_types)}. "
    prompt = f"""
ë„ˆëŠ” ë˜‘ë˜‘í•œ êµìœ¡ìš© ì„ ìƒë‹˜ì´ì•¼. ì•„ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í€´ì¦ˆë¥¼ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì¤˜.
ì˜ˆì‹œ:[{{"type":"ê°ê´€ì‹","question":"ì˜ˆì‹œ","options":["A","B","C","D"],"answer":"A","explanation":"í•´ì„¤"}}]
- {type_hint}ë¬¸ì œë§ˆë‹¤ 'type','question','answer','explanation' í¬í•¨
- 'options'ëŠ” ê°ê´€ì‹/OXì—ì„œë§Œ í¬í•¨
- JSON ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥
- ì´ {quiz_count}ë¬¸ì œ
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":prompt},{"role":"user","content":content}]
        )
        raw = resp.choices[0].message.content.strip()
        if raw.startswith("```"):
            raw = raw.strip("`").lstrip("json").strip()
        parsed = safe_load_json5(raw)
        if isinstance(parsed, list) and allowed_types:
            filtered = [q for q in parsed if (q.get("type") or "").strip() in allowed_types]
            if len(filtered) >= 1:
                return filtered[:quiz_count]
        return parsed[:quiz_count] if isinstance(parsed, list) else []
    except Exception as e:
        st.error(f"âŒ í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        return []

def summarize_content(content):
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role":"system","content":"ì•„ë˜ ë‚´ìš©ì„ 3~5ì¤„ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜."},
                {"role":"user","content":content}
            ]
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"âŒ ìš”ì•½ ì‹¤íŒ¨: {e}")
        return "ìš”ì•½ ì‹¤íŒ¨"

def ask_gpt_about_wrong(problem, user_answer):
    prompt = f"ë¬¸ì œ: {problem['question']}\nì •ë‹µ: {problem['answer']}\në‚´ ì˜¤ë‹µ: {user_answer}\nì™œ í‹€ë ¸ëŠ”ì§€ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜."
    resp = client.chat.completions.create(
        model=model, messages=messages, temperature=temperature, max_tokens=max_tokens
    )
    return resp.choices[0].message.content.strip()

def target_lines_for_length(n_chars: int) -> int:
    if n_chars < 1500: return 4
    elif n_chars < 5000: return 6
    elif n_chars < 12000: return 8
    elif n_chars < 25000: return 10
    elif n_chars < 50000: return 13
    else: return 16

def summarize_large_text(text, target_lines=8, base_chunk_chars=7000, reduce_chunk_chars=4000):
    if not text or len(text.strip()) == 0: return ""
    chunks = split_text_by_chars(text, base_chunk_chars)
    part_summaries = []
    if len(chunks) == 1:
        sys = f"ì•„ë˜ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜."
        return gpt_chat(
            [{"role": "system", "content": sys},
             {"role": "user", "content": chunks[0]}]
        )
    prog = st.progress(0.0, text="1/3 ë‹¨ê³„: ë¶€ë¶„ ìš”ì•½ ì¤‘...")
    for i, ck in enumerate(chunks, start=1):
        sys = "ì•„ë˜ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë…¼ì§€/í‚¤ì›Œë“œ/ìˆ«ìë§Œ 5~7ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½."
        ps = gpt_chat([{"role":"system","content":sys},{"role":"user","content":ck}])
        part_summaries.append(ps); prog.progress(i/len(chunks))
    combined = "\n\n".join(part_summaries)
    reduce_chunks = split_text_by_chars(combined, reduce_chunk_chars)
    reduce_summaries = []
    prog = st.progress(0.0, text="2/3 ë‹¨ê³„: ìš”ì•½ í†µí•© ì¤‘...")
    for i, rc in enumerate(reduce_chunks, start=1):
        sys2 = "ì•„ë˜ ìš”ì•½ë“¤ì„ ì¤‘ë³µ ì œê±°í•˜ê³  í•µì‹¬ë§Œ ì••ì¶•í•´ 4~6ë¬¸ì¥ìœ¼ë¡œ ì¬ìš”ì•½."
        rs = gpt_chat([{"role":"system","content":sys2},{"role":"user","content":rc}])
        reduce_summaries.append(rs); prog.progress(i/len(reduce_chunks))
    final_source = "\n\n".join(reduce_summaries)
    sys3 = f"ì „ì²´ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ, ìˆ«ì/ê³ ìœ ëª…ì‚¬ ìœ ì§€í•˜ë©° ìµœì¢… ìš”ì•½."
    prog = st.progress(0.0, text="3/3 ë‹¨ê³„: ìµœì¢… ìš”ì•½ ì •ë¦¬ ì¤‘...")
    final = gpt_chat([{"role":"system","content":sys3},{"role":"user","content":final_source}])
    prog.progress(1.0); return final

def summarize_content(content: str):
    if not content or not content.strip(): return "ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    n = len(content); target_lines = target_lines_for_length(n)
    st.info(f"ğŸ“ ë¬¸ì„œ ê¸¸ì´: ì•½ {n:,}ì â†’ ëª©í‘œ ìš”ì•½: **{target_lines}ì¤„**")
    if n <= 5000:
        try:
            sys = f"ì•„ë˜ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜."
            return gpt_chat([{"role":"system","content":sys},{"role":"user","content":content}])
        except Exception:
            return summarize_large_text(content, target_lines=target_lines)
    else:
        return summarize_large_text(content, target_lines=target_lines)

# =========================
# í€´ì¦ˆ ìƒì„±/ì˜¤ë‹µ í•´ì„¤
# =========================
def _safe_json_parse(s: str):
    s = s.strip()
    # JSON ì½”ë“œë¸”ë¡ë§Œ ì¶”ì¶œ ì‹œë„
    m = re.search(r"\[.*\]", s, flags=re.S)
    if m: s = m.group(0)
    try:
        import json5
        return json5.loads(s)
    except Exception:
        return json.loads(s)

def generate_quiz(content: str, count: int = 8, allowed_types: set = None):
    """
    ë°˜í™˜: list[ {type, question, options, answer, explanation}, ... ]
    type âˆˆ {"ê°ê´€ì‹","OX","ë‹¨ë‹µí˜•"}
    """
    if not content.strip(): return []
    if not allowed_types:
        allowed_types = {"ê°ê´€ì‹","OX","ë‹¨ë‹µí˜•"}

    system = (
        "ë„ˆëŠ” í•œêµ­ì–´ í•™ìŠµìš© í€´ì¦ˆ ì¶œì œ ë„ìš°ë¯¸ì•¼. "
        "í•­ìƒ JSONë§Œ ì¶œë ¥í•´. ì„¤ëª… í…ìŠ¤íŠ¸ ê¸ˆì§€."
    )
    user = f"""
ë‹¤ìŒ í•™ìŠµ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í€´ì¦ˆ {count}ë¬¸ì œë¥¼ ìƒì„±í•´.
í—ˆìš© ìœ í˜•: {sorted(list(allowed_types))}
- ê° ë¬¸ì œëŠ” ê°ì²´ë¡œ êµ¬ì„±: {{"type":"ê°ê´€ì‹|OX|ë‹¨ë‹µí˜•","question":"ë¬¸ì œ",
                            "options":["ë³´ê¸°1","ë³´ê¸°2",...], "answer":"ì •ë‹µ ë˜ëŠ” [ì •ë‹µë“¤]",
                            "explanation":"ì™œ ì •ë‹µì¸ì§€ ê°„ë‹¨ í•´ì„¤"}}
- "ê°ê´€ì‹"ì€ ìµœì†Œ 4ì§€ì„ ë‹¤, "OX"ëŠ” ["O","X"]ë¥¼ optionsë¡œ, "ë‹¨ë‹µí˜•"ì€ optionsëŠ” ë¹ˆ ë¦¬ìŠ¤íŠ¸ í—ˆìš©.
- ê· í˜•ìˆê²Œ ì„ë˜, í—ˆìš©ëœ ìœ í˜•ë§Œ ì‚¬ìš©.
- JSON ë°°ì—´ë§Œ ì¶œë ¥.
ë‚´ìš©:
\"\"\"{content[:20000]}\"\"\"  # (ìµœëŒ€ 2ë§Œìë§Œ ì‚¬ìš©)
"""
    try:
        raw = gpt_chat(
            [{"role":"system","content":system},{"role":"user","content":user}],
            model=MODEL_SUMMARY,
            temperature=0.2,
            max_tokens=2000
        )
        data = _safe_json_parse(raw)
        if not isinstance(data, list): return []
        # ì •ê·œí™”
        norm = []
        for item in data:
            qtype = (item.get("type","") or "").strip()
            if qtype not in {"ê°ê´€ì‹","OX","ë‹¨ë‹µí˜•"}: continue
            q = {
                "type": qtype,
                "question": item.get("question","").strip(),
                "options": item.get("options", []) or ([] if qtype=="ë‹¨ë‹µí˜•" else (["O","X"] if qtype=="OX" else [])),
                "answer": item.get("answer", ""),
                "explanation": item.get("explanation", "")
            }
            # OX ì˜µì…˜ ê°•ì œ
            if qtype == "OX":
                q["options"] = ["O","X"]
            norm.append(q)
        # ê°œìˆ˜ ë§ì¶”ê¸°
        if len(norm) > count: norm = norm[:count]
        return norm
    except Exception:
        return []

def ask_gpt_about_wrong(qobj: dict, user_answer: str) -> str:
    question = qobj.get("question","")
    answer   = qobj.get("answer","")
    expl     = qobj.get("explanation","")
    opts     = qobj.get("options", [])
    system = "ë„ˆëŠ” í•œêµ­ì–´ êµì‚¬ì•¼. í•™ìƒì˜ ì˜¤ë‹µì— ëŒ€í•´ ì§§ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´."
    user = f"""ë¬¸ì œ: {question}
ì„ íƒì§€: {opts}
í•™ìƒì˜ ë‹µ: {user_answer}
ì •ë‹µ: {answer}
ê¸°ì¡´ í•´ì„¤(ìˆìœ¼ë©´ í™œìš©): {expl}
ìš”ì²­: ì™œ ì˜¤ë‹µì¸ì§€/ì™œ ì •ë‹µì´ ë§ëŠ”ì§€ 3~5ë¬¸ì¥ìœ¼ë¡œ ê°„ë‹¨íˆ ì„¤ëª…í•˜ê³ , í•µì‹¬ ê°œë…ì„ 1~2ê°œ í‚¤ì›Œë“œë¡œ ìš”ì•½í•´ì¤˜."""
    try:
        return gpt_chat([{"role":"system","content":system},{"role":"user","content":user}], model=MODEL_SUMMARY, temperature=0.2, max_tokens=500)
    except Exception:
        return expl or "í•´ì„¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

# =========================
# ìƒë‹¨ ë¦¬í”„ë ˆì‹œ
# =========================
st.markdown("<div style='text-align:right'>", unsafe_allow_html=True)
if st.button("ğŸ”„ ì „ì²´ ìƒˆë¡œê³ ì¹¨", key="refresh_all"):
    for k in list(st.session_state.keys()):
        del st.session_state[k]
    st.rerun()
st.markdown("</div>", unsafe_allow_html=True)

# =========================
# íƒ­ êµ¬ì„±
# =========================
tab1, tab2 = st.tabs(["ğŸ“„ PDF ìš”ì•½", "ğŸ§  í€´ì¦ˆ ìƒì„±ê¸°"])

# -------------------------------------------------------------------
# TAB 1: PDF ìš”ì•½ (RAG í¬í•¨)
# -------------------------------------------------------------------
with tab1:
    st.title("ğŸ¾ ë”¸ê¹ê³µ Â· PDF ìš”ì•½ (RAG + ì„ íƒ êµ¬ê°„)")
    uploaded = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"], key="pdf_uploader_main")

    if not uploaded:
        st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ **í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ í™•ë³´** â†’ (í•„ìš”ì‹œ) **ë²¡í„°DB ì¸ë±ì‹±** â†’ ì›í•˜ëŠ” **í˜ì´ì§€ ë²”ìœ„ë§Œ RAG ìš”ì•½**í•  ìˆ˜ ìˆì–´ìš”.")
    else:
        pdf_bytes = uploaded.read()

        # --- RAG ìœ í‹¸ ë¡œë“œ ---
        have_rag = True
        try:
            from lib.rag_utils import (
                upsert_doc, doc_exists, _sha1_bytes,
                rag_summarize_section, format_context
            )
        except Exception:
            have_rag = False
            st.warning("âš ï¸ RAG ëª¨ë“ˆ(lib/rag_utils.py)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. 'ì¼ë°˜ ìš”ì•½'ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.")

        doc_id = None
        total_pages = 0
        pages_text = []

        if have_rag:
            doc_id_guess = _sha1_bytes(pdf_bytes)
            if doc_exists(doc_id_guess):
                # âœ… ì¸ë±ì‹±ëœ ë¬¸ì„œ: OCR/í…ìŠ¤íŠ¸ ì¶”ì¶œ ìƒëµ
                doc_id = doc_id_guess
                st.info(f"âœ… ì´ë¯¸ ì¸ë±ì‹±ë¨: doc_id={doc_id} (í…ìŠ¤íŠ¸ ì¶”ì¶œ/OCR ê±´ë„ˆëœ€)")
                # í˜ì´ì§€ ìˆ˜ë§Œ ë¹ ë¥´ê²Œ ê³„ì‚°
                try:
                    from PyPDF2 import PdfReader
                    total_pages = len(PdfReader(io.BytesIO(pdf_bytes)).pages)
                except Exception:
                    total_pages = 1
            else:
                with st.spinner("PDF í˜ì´ì§€ í…ìŠ¤íŠ¸ í™•ë³´ ì¤‘â€¦"):
                    pages_text, total_pages = pdf_pages_to_texts(
                        pdf_bytes,
                        dpi=120,
                        min_chars_for_pdftext=10
                    )

                if total_pages == 0:
                    st.error("PDFì—ì„œ í˜ì´ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    st.stop()

                with st.spinner("ë²¡í„°DB ì¸ë±ì‹± ì¤‘â€¦ (ì¬ì¸ë±ì‹± ë°©ì§€)"):
                    added, doc_id = upsert_doc(
                        pages_text,
                        source_name=uploaded.name,
                        file_bytes=pdf_bytes,
                        chunk_size=800, overlap=200,
                        force=False
                    )
                st.success(f"ğŸ“¦ ì¸ë±ì‹± ìƒíƒœ â€” í˜ì´ì§€ {total_pages} / ì‹ ê·œ ì²­í¬ {added}ê°œ (doc_id: {doc_id})")
        else:
            # RAG ì—†ìŒ â†’ í•­ìƒ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            with st.spinner("PDF í˜ì´ì§€ í…ìŠ¤íŠ¸ í™•ë³´ ì¤‘â€¦"):
                pages_text, total_pages = pdf_pages_to_texts(
                    pdf_bytes,
                    dpi=120,
                    min_chars_for_pdftext=10
                )
            if total_pages == 0:
                st.error("PDFì—ì„œ í˜ì´ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                st.stop()

        # --- êµ¬ê°„ ì„ íƒ UI ---
        st.subheader("ğŸ“Œ ìš”ì•½ êµ¬ê°„ ì„ íƒ")
        if total_pages > 1:
            page_s, page_e = st.slider("í˜ì´ì§€ ë²”ìœ„", 1, total_pages, (1, min(5, total_pages)))
        else:
            page_s, page_e = 1, 1
            st.caption("ë¬¸ì„œê°€ 1í˜ì´ì§€ì…ë‹ˆë‹¤.")

        query = st.text_input("ìš”ì•½ ì£¼ì œ/ì§ˆë¬¸(ì„ íƒ, ê³µë°±ì´ë©´ 'í•µì‹¬ ìš”ì•½')", value="í•µì‹¬ ìš”ì•½")

        c1, c2 = st.columns(2)
        with c1:
            if have_rag and st.button("ğŸ“ ì„ íƒ êµ¬ê°„ë§Œ RAG ìš”ì•½", use_container_width=True):
                with st.spinner("ì„ íƒ êµ¬ê°„ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë° ìš”ì•½ ì¤‘â€¦"):
                    out = rag_summarize_section(
                        client=client,
                        model=MODEL_SUMMARY,
                        doc_id=doc_id,
                        query=query or "í•µì‹¬ ìš”ì•½",
                        page_range=(page_s, page_e),
                        max_chars_context=9000,
                        top_k=16
                    )
                st.markdown("### âœ… ìš”ì•½ ê²°ê³¼ (ì„ íƒ êµ¬ê°„/RAG)")
                st.write(out["summary"])
                st.session_state["summary"] = out["summary"]
                with st.expander("ğŸ” ê·¼ê±° ì»¨í…ìŠ¤íŠ¸ ë³´ê¸°"):
                    st.code(format_context(out["evidence"]))

        with c2:
            if st.button("ğŸ“„ ì „ì²´ ë¬¸ì„œ ì¼ë°˜ ìš”ì•½", use_container_width=True):
                if not pages_text:  # ì¸ë±ì‹±ëœ ë¬¸ì„œë©´ ë‹¤ì‹œ ì¶”ì¶œ
                    pages_text, _ = pdf_pages_to_texts(
                        pdf_bytes,
                        dpi=120,
                        min_chars_for_pdftext=10
                    )
                all_text = "\n\n".join([t for _, t in pages_text])
                res = summarize_content(all_text)
                st.markdown("### ğŸ§¾ ì „ì²´ ìš”ì•½ (ì¼ë°˜)")
                st.write(res)
                st.session_state["summary"] = res

            if have_rag and st.button("ğŸ§  ì „ì²´ ë¬¸ì„œ RAG ìš”ì•½(ê·¼ê±°)", use_container_width=True):
                with st.spinner("ì „ì²´ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰(RAG) ë° ìš”ì•½ ì¤‘â€¦"):
                    out = rag_summarize_section(
                        client=client,
                        model=MODEL_SUMMARY,
                        doc_id=doc_id,
                        query=(query or "ì „ì²´ í•µì‹¬ ìš”ì•½"),
                        page_range=(1, total_pages),
                        max_chars_context=9000,
                        top_k=16
                    )
                st.markdown("### âœ… ì „ì²´ ë¬¸ì„œ RAG ìš”ì•½ (ê·¼ê±° í¬í•¨)")
                st.write(out["summary"])
                st.session_state["summary"] = out["summary"]
                with st.expander("ğŸ” ê·¼ê±° ì»¨í…ìŠ¤íŠ¸ ë³´ê¸°"):
                    st.code(format_context(out["evidence"]))

        st.caption("ğŸ’¡ ìš”ì•½ ê²°ê³¼ëŠ” ìë™ìœ¼ë¡œ í€´ì¦ˆ íƒ­ì— ì „ë‹¬ë©ë‹ˆë‹¤.")


# -------------------------------------------------------------------
# TAB 2: í€´ì¦ˆ ìƒì„±ê¸°
# -------------------------------------------------------------------
with tab2:
    if "quiz_stage" not in st.session_state:
        st.session_state.quiz_stage = "setup"

    # ========== SETUP ==========
    if st.session_state.quiz_stage == "setup":
        st.markdown('<div class="section"><div class="section-header">í€´ì¦ˆ ìƒì„±ê¸°</div><div class="section-body">', unsafe_allow_html=True)

        c1, c2, c3 = st.columns([1,2,2], gap="large")
        with c1:
            quiz_count = st.number_input("ë¬¸í•­ ìˆ˜", min_value=4, max_value=20, value=8, step=1, key="count_input")
            shuffle = st.checkbox("ì„ íƒì§€ ì„ê¸°", value=True, key="shuffle_input")
        with c2:
            st.markdown("**ìœ í˜• ì„ íƒ**")
            t_obj = st.checkbox("ê°ê´€ì‹", value=True, key="t_obj")
            t_ox  = st.checkbox("OX", value=True, key="t_ox")
            t_sa  = st.checkbox("ë‹¨ë‹µí˜•", value=True, key="t_sa")
            allowed_types = [t for t, ok in [("ê°ê´€ì‹", t_obj), ("OX", t_ox), ("ë‹¨ë‹µí˜•", t_sa)] if ok]
        with c3:
            content_default = st.session_state.get("summary", "")
            content_input = st.text_area("âœï¸ í•™ìŠµ ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ PDF ìš”ì•½ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”",
                                         value=content_default,
                                         height=120, key="quiz_content_input")
            st.caption("âœ… PDF ìš”ì•½ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì±„ì›Œì§‘ë‹ˆë‹¤.")

        if st.button("ğŸ§  í€´ì¦ˆ ìƒì„±í•˜ê¸°", key="make_quiz"):
            content_to_use = (st.session_state.get("quiz_content_input","") or "").strip()
            if not content_to_use:
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ ìš”ì•½ ê²°ê³¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("GPTê°€ í€´ì¦ˆë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    # ê°„ë‹¨ í•™ìŠµ ìš”ì•½ ë¡œê·¸ (ì„ íƒ)
                    st.session_state.summary_log = summarize_content(content_to_use)
                    data = generate_quiz(content_to_use, st.session_state.count_input, allowed_types=set(allowed_types))
                    if not data:
                        st.error("í€´ì¦ˆ ìƒì„±ì— ì‹¤íŒ¨í–ˆì–´ìš”. ë‚´ìš©ì„ ì¡°ê¸ˆ ë” ê¸¸ê²Œ ì…ë ¥í•´ë³´ì„¸ìš”.")
                    else:
                        if st.session_state.shuffle_input:
                            for q in data:
                                if (q.get("type") in ["ê°ê´€ì‹","OX"]) and isinstance(q.get("options"), list):
                                    random.shuffle(q["options"])
                        st.session_state.quiz_data = data
                        st.session_state.user_answers = {}
                        st.session_state.current_idx = 0
                        st.session_state.graded = False
                        st.session_state.score = 0
                        st.session_state.quiz_stage = "play"
                        st.rerun()

        # ìš”ì•½ ë¯¸ë¦¬ë³´ê¸°(ì„ íƒ)
        if st.session_state.get("summary_log"):
            st.info(f"ğŸ“š í•™ìŠµ ìš”ì•½:\n\n{st.session_state.summary_log}")

        st.markdown('</div></div>', unsafe_allow_html=True)  # section-body/section ë‹«ê¸°

    # ========== PLAY ==========
    elif st.session_state.quiz_stage == "play":
        # ì•ˆì „ê°€ë“œ
        if not st.session_state.get("quiz_data"):
            st.session_state.quiz_stage = "setup"
            st.rerun()

        # ìƒë‹¨: ë’¤ë¡œê°€ê¸°
        back_col, _ = st.columns([1,5])
        with back_col:
            if st.button("â† ë‹¤ì‹œ ìƒì„±", key="back_setup"):
                for k in ["quiz_data","user_answers","current_idx","graded","score","summary_log"]:
                    if k in st.session_state: del st.session_state[k]
                st.session_state.quiz_stage = "setup"
                st.rerun()

        # ë‚´ë¶€ ìœ í‹¸
        def _normalize(s):
            if isinstance(s, (list, tuple)): return [str(x).strip().lower() for x in s]
            return str(s).strip().lower()
        def _is_correct(user, answer):
            u_ = _normalize(user); a_ = _normalize(answer)
            if isinstance(a_, list): return u_ in a_
            return u_ == a_

        # ë Œë”ëŸ¬
        def _render_player():
            qlist = st.session_state.quiz_data
            idx = st.session_state.current_idx
            total = len(qlist)
            q = qlist[idx]
            qtype = (q.get("type","") or "").strip()

            st.markdown('<div class="quiz-shell">', unsafe_allow_html=True)
            st.markdown('<div class="quiz-header">í€´ì¦ˆ í’€ê¸°</div>', unsafe_allow_html=True)
            st.markdown('<div class="quiz-body">', unsafe_allow_html=True)

            st.markdown(f'<div class="quiz-meta">{idx+1}/{total}</div>', unsafe_allow_html=True)
            st.markdown(f'<div class="quiz-question">{q.get("question","-")}</div>', unsafe_allow_html=True)

            if qtype in ["ê°ê´€ì‹","OX"]:
                options = q.get("options", []) or (["O","X"] if qtype=="OX" else [])
                letters = ["A","B","C","D","E","F"]
                if idx not in st.session_state.user_answers:
                    st.session_state.user_answers[idx] = None

                def tile(opt_text, letter, k, selected):
                    st.markdown(f"<div class='opt2{' selected' if selected else ''}'>", unsafe_allow_html=True)
                    clicked = st.button(f"{letter}  {opt_text}", key=k, use_container_width=True)
                    st.markdown("</div>", unsafe_allow_html=True)
                    return clicked

                for r in range(0, len(options), 2):
                    g1, g2 = st.columns(2, gap="small")
                    with g1:
                        if r < len(options):
                            opt = options[r]
                            sel = (st.session_state.user_answers[idx] == opt)
                            if tile(opt, letters[r], f"nopt_{idx}_{r}", sel):
                                st.session_state.user_answers[idx] = opt
                    with g2:
                        if r+1 < len(options):
                            opt = options[r+1]
                            sel = (st.session_state.user_answers[idx] == opt)
                            if tile(opt, letters[r+1], f"nopt_{idx}_{r+1}", sel):
                                st.session_state.user_answers[idx] = opt
            else:
                key = f"sa_{idx}"
                val = st.text_input("ì •ë‹µì„ ì…ë ¥í•˜ì„¸ìš”", key=key)
                st.session_state.user_answers[idx] = val

            # ë„¤ë¹„
            st.markdown('<div class="action-row">', unsafe_allow_html=True)
            cprev, cnext = st.columns([1,1], gap="small")
            with cprev:
                st.markdown('<div class="prev-btn">', unsafe_allow_html=True)
                if st.button("ì´ì „", key=f"prev_{idx}") and st.session_state.current_idx > 0:
                    st.session_state.current_idx -= 1
                st.markdown('</div>', unsafe_allow_html=True)
            with cnext:
                st.markdown('<div class="next-btn">', unsafe_allow_html=True)
                if idx < total-1:
                    if st.button("ë‹¤ìŒ", key=f"next_{idx}"):
                        st.session_state.current_idx += 1
                else:
                    if st.button("ì œì¶œ/ì±„ì ", key="submit_all"):
                        score = 0
                        for i, qq in enumerate(qlist):
                            user = st.session_state.user_answers.get(i, "")
                            if _is_correct(user, qq.get("answer","")):
                                score += 1
                        st.session_state.score = score
                        st.session_state.graded = True
                st.markdown('</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)  # action-row
            st.markdown('</div>', unsafe_allow_html=True)  # quiz-body
            st.markdown('</div>', unsafe_allow_html=True)  # quiz-shell

        # ë Œë”/ê²°ê³¼
        _render_player()

        if st.session_state.get("graded"):
            total = len(st.session_state.quiz_data)
            score = st.session_state.get("score", 0)
            st.markdown(f"<span class='score-pill'>ì ìˆ˜: {score} / {total}</span>", unsafe_allow_html=True)
            ratio = score/total if total else 0
            st.markdown(
                'ğŸ‰ <span class="result-good">ì˜í–ˆì–´ìš”!</span>' if ratio >= 0.6 
                else 'ğŸ’ª <span class="result-bad">ì¡°ê¸ˆë§Œ ë”!</span>',
                unsafe_allow_html=True
            )

            wrongs = []
            for i, q in enumerate(st.session_state.quiz_data):
                user = st.session_state.user_answers.get(i, "")
                if not _is_correct(user, q.get("answer","")):
                    wrongs.append((i, q, user))
            if wrongs:
                st.markdown("---")
                st.markdown("#### ì˜¤ë‹µ í•´ì„¤")
                for i, q, user in wrongs:
                    with st.expander(f"ë¬¸ì œ {i+1} - ë‚´ ë‹µ: {user} / ì •ë‹µ: {q.get('answer','')}", expanded=False):
                        try:
                            why = ask_gpt_about_wrong(q, user)
                        except Exception:
                            why = q.get("explanation","")
                        st.write(why)