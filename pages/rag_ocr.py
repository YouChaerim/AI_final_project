# app.py
# -*- coding: utf-8 -*- (ìœ ë‹ˆì½”ë“œë¡œ ìˆ˜ì • 2025/07/25)
import io, os, re, gc
import numpy as np
import streamlit as st
import cv2
from PIL import Image
from dotenv import load_dotenv
from openai import OpenAI
from PyPDF2 import PdfReader
from pdf2image import convert_from_bytes
from pdf2image.exceptions import PDFInfoNotInstalledError

# ===== âœ… .envì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° =====
load_dotenv(dotenv_path="C:/Users/user/Desktop/main_project/.env")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
POPPLER_PATH   = os.getenv("POPPLER_PATH")  # ì„ íƒ: pdf2image ê²½ë¡œ ì§€ì •(poppler)
# ì˜ˆ) POPPLER_PATH=C:/Users/user/anaconda3/envs/final/Library/bin

# ===== í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • =====
st.set_page_config(page_title="ğŸ“„ OCR + GPT ìš”ì•½/í€´ì¦ˆ ìƒì„±ê¸°",
                   layout="centered",
                   initial_sidebar_state="collapsed")
st.markdown("""
<style>
[data-testid="stSidebar"]{display:none!important;}
.stTextArea textarea{font-size:.95rem;line-height:1.5;}
.stAlert{margin-top:.5rem;}
</style>
""", unsafe_allow_html=True)

# ===== âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ìºì‹± =====
@st.cache_resource
def get_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("âŒ .env íŒŒì¼ì—ì„œ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    return OpenAI(api_key=api_key)

client = get_openai_client()
MODEL_SUMMARY = "gpt-4o-mini"   # í•„ìš” ì‹œ êµì²´

# ===== âœ… PaddleOCR ìºì‹± (í˜¸í™˜í˜•) =====
# ===== âœ… PaddleOCR ìºì‹± (í˜¸í™˜í˜•) =====
@st.cache_resource
def get_ocr():
    from paddleocr import PaddleOCR
    # ê°€ì¥ ë³´ìˆ˜ì ìœ¼ë¡œ: ì§€ì› ê°€ëŠ¥ì„±ì´ ë†’ì€ ì¸ìë¶€í„° ì‹œë„
    for kwargs in [
        dict(lang="korean", use_angle_cls=True),
        dict(lang="korean"),
        dict(),  # ìµœí›„ì˜ ìˆ˜ë‹¨: ì™„ì „ ê¸°ë³¸ê°’
    ]:
        try:
            return PaddleOCR(**kwargs)
        except TypeError:
            continue
    st.error("PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: ì„¤ì¹˜ëœ ë²„ì „ì´ ì¸ìë“¤ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    st.stop()


def _prep_im_for_ocr(pil_img: Image.Image, max_side: int = 2000) -> np.ndarray:
    """PIL -> ì•ˆì „ BGR, ê¸´ ë³€ max_sideë¡œ ì¶•ì†Œ(ì•ˆì •/ì†ë„ìš©)"""
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    arr = np.array(pil_img)                 # RGB
    arr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)
    h, w = arr.shape[:2]
    m = max(h, w)
    if m > max_side:
        scale = max_side / float(m)
        arr = cv2.resize(arr, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_LINEAR)
    return np.ascontiguousarray(arr)

def _group_runs(pages):
    """ì˜ˆ: [3,4,5, 9,10] -> [(3,5), (9,10)] (ì—°ì† êµ¬ê°„ ë¬¶ê¸°)"""
    if not pages: return []
    runs, s, e = [], pages[0], pages[0]
    for p in pages[1:]:
        if p == e + 1:
            e = p
        else:
            runs.append((s, e))
            s = e = p
    runs.append((s, e))
    return runs

@st.cache_data(show_spinner=False)
def pdf_pages_to_texts(
    pdf_bytes: bytes,
    *,
    dpi: int = 120,
    min_chars_for_pdftext: int = 10,
):
    """
    1) ë‚´ì¥ í…ìŠ¤íŠ¸ ìš°ì„ 
    2) ì»¤ë²„ë¦¬ì§€ì— ë”°ë¼ ìë™ ì •ì±…:
       - >=70%: í…ìŠ¤íŠ¸ë§Œ
       - 30~70%: í•˜ì´ë¸Œë¦¬ë“œ(ë¶€ì¡± í˜ì´ì§€ë§Œ OCR)
       - <30%: ì „ì²´ OCR
    return: [(page_no, text), ...], total_pages
    """
    # 1) ë‚´ì¥ í…ìŠ¤íŠ¸
    try:
        reader = PdfReader(io.BytesIO(pdf_bytes))
        base_pages = [(i+1, (p.extract_text() or "")) for i, p in enumerate(reader.pages)]
    except Exception:
        base_pages = []
    total_pages = len(base_pages)

    # ë‚´ì¥ í…ìŠ¤íŠ¸ ìì²´ê°€ ì—†ìœ¼ë©´ â†’ ì „ì²´ OCR ì‹œë„
    if total_pages == 0:
        try:
            images = convert_from_bytes(pdf_bytes, dpi=dpi)
        except PDFInfoNotInstalledError:
            st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: OCR ì‚¬ìš© ë¶ˆê°€")
            return [], 0
        ocr = get_ocr()
        out, prog = [], st.progress(0.0, text=f"OCR ì „ì²´ ì§„í–‰ ì¤‘â€¦ ({len(images)}p, DPI={dpi})")
        for i, img in enumerate(images, start=1):
            arr = _prep_im_for_ocr(img, max_side=2000)
            res = ocr.ocr(arr)
            txt = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            out.append((i, txt))
            prog.progress(i/len(images))
            del img
        prog.empty()
        st.caption("ëª¨ë“œ: ì „ì²´ OCR (ë‚´ì¥ í…ìŠ¤íŠ¸ ì—†ìŒ)")
        return out, len(images)

    # 2) ì»¤ë²„ë¦¬ì§€ ê³„ì‚°
    lengths = [len((t or "").strip()) for _, t in base_pages]
    text_pages = sum(1 for L in lengths if L >= min_chars_for_pdftext)
    coverage = text_pages / max(1, total_pages)

    if coverage >= 0.70:
        # âœ… ë‚´ì¥ í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì¶©ë¶„
        st.caption(f"ëª¨ë“œ: í…ìŠ¤íŠ¸ë§Œ (ì»¤ë²„ë¦¬ì§€ {coverage:.0%})")
        return base_pages, total_pages

    if coverage < 0.30:
        # ğŸ–¨ ìŠ¤ìº”ë³¸ íŒë‹¨ â†’ ì „ì²´ OCR
        try:
            images = convert_from_bytes(pdf_bytes, dpi=dpi)
        except PDFInfoNotInstalledError:
            st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: ì „ì²´ OCR ë¶ˆê°€ â†’ ë‚´ì¥ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©")
            st.caption(f"ëª¨ë“œ: í…ìŠ¤íŠ¸ë§Œ (ì»¤ë²„ë¦¬ì§€ {coverage:.0%}, OCR ë¶ˆê°€)")
            return base_pages, total_pages
        ocr = get_ocr()
        out, prog = [], st.progress(0.0, text=f"OCR ì „ì²´ ì§„í–‰ ì¤‘â€¦ ({len(images)}p, DPI={dpi})")
        for i, img in enumerate(images, start=1):
            arr = _prep_im_for_ocr(img, max_side=2000)
            res = ocr.ocr(arr)
            txt = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            out.append((i, txt))
            prog.progress(i/len(images))
            del img
        prog.empty()
        st.caption(f"ëª¨ë“œ: ì „ì²´ OCR (ì»¤ë²„ë¦¬ì§€ {coverage:.0%})")
        return out, len(images)

    # 3) í•˜ì´ë¸Œë¦¬ë“œ: ë¶€ì¡± í˜ì´ì§€ë§Œ OCR (ì—°ì† êµ¬ê°„ ë¬¶ì–´ì„œ ë Œë”ë§ ìµœì†Œí™”)
    need_pages = [pg for (pg, t) in base_pages if len((t or "").strip()) < min_chars_for_pdftext]
    runs = _group_runs(need_pages)
    page_to_text = {pg: (t or "") for pg, t in base_pages}
    ocr = get_ocr()

    done = 0
    prog = st.progress(0.0, text=f"í•˜ì´ë¸Œë¦¬ë“œ: ë¶€ì¡± í˜ì´ì§€ë§Œ OCR ì¤‘â€¦ (ì´ {len(need_pages)}p, DPI={dpi})")
    for s, e in runs:
        try:
            imgs = convert_from_bytes(pdf_bytes, dpi=dpi, first_page=s, last_page=e)
        except PDFInfoNotInstalledError:
            st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: OCR ë³´ì¶© ìƒëµ â†’ ë‚´ì¥ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©")
            break
        for idx, pg in enumerate(range(s, e+1)):
            arr = _prep_im_for_ocr(imgs[idx], max_side=2000)
            res = ocr.ocr(arr)
            t2 = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            page_to_text[pg] = t2
            done += 1
            prog.progress(done / max(1, len(need_pages)))
        del imgs
    prog.empty()
    out = [(pg, page_to_text.get(pg, "")) for pg, _ in base_pages]
    st.caption(f"ëª¨ë“œ: í•˜ì´ë¸Œë¦¬ë“œ (ì»¤ë²„ë¦¬ì§€ {coverage:.0%}, OCR {len(need_pages)}p)")
    return out, total_pages


# ===== RAG ìœ í‹¸ ê°€ì ¸ì˜¤ê¸° =====
try:
    from lib.rag_utils import (
        upsert_doc, doc_exists, _sha1_bytes,
        rag_summarize_section, format_context
    )
except Exception:
    st.error("âŒ lib/rag_utils.py ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ìµœì‹  ë²„ì „ì´ ì•„ë‹™ë‹ˆë‹¤.\n"
             "ì´ì „ì— ì œê³µí•œ bge-m3 í†µí•©íŒì„ ì €ì¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ====== í…ìŠ¤íŠ¸/ìš”ì•½ ìœ í‹¸ ======
def extract_pdf_text_if_possible(pdf_file) -> list[tuple[int, str]]:
    """í˜ì´ì§€ë³„ ë‚´ì¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ(ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´). return [(page_no, text), ...]"""
    try:
        reader = PdfReader(pdf_file)
        return [(i+1, (p.extract_text() or "")) for i, p in enumerate(reader.pages)]
    except Exception:
        return []

def split_text_by_chars(s: str, max_chars: int):
    paras = re.split(r"\n{2,}", s)
    chunks, buff = [], ""
    for p in paras:
        p = p.strip()
        if not p: continue
        if len(buff) + len(p) + 2 <= max_chars:
            buff = (buff + "\n\n" + p).strip()
        else:
            if buff: chunks.append(buff)
            if len(p) > max_chars:
                sents = re.split(r"(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+", p)
                cur = ""
                for sent in sents:
                    if len(cur) + len(sent) + 1 <= max_chars:
                        cur = (cur + " " + sent).strip()
                    else:
                        if cur: chunks.append(cur)
                        cur = sent
                if cur: chunks.append(cur)
            else:
                buff = p
    if buff: chunks.append(buff)
    return chunks

def gpt_chat(messages, model=MODEL_SUMMARY, temperature=0.2, max_tokens=None):
    resp = client.chat.completions.create(
        model=model, messages=messages, temperature=temperature, max_tokens=max_tokens
    )
    return resp.choices[0].message.content.strip()

def target_lines_for_length(n_chars: int) -> int:
    if n_chars < 1500: return 4
    elif n_chars < 5000: return 6
    elif n_chars < 12000: return 8
    elif n_chars < 25000: return 10
    elif n_chars < 50000: return 13
    else: return 16

def summarize_large_text(text, target_lines=8, base_chunk_chars=7000, reduce_chunk_chars=4000):
    if not text or len(text.strip()) == 0: return ""
    chunks = split_text_by_chars(text, base_chunk_chars)
    part_summaries = []
    if len(chunks) == 1:
        sys = f"ì•„ë˜ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜."
        return gpt_chat(
            [{"role": "system", "content": sys},
             {"role": "user", "content": chunks[0]}]
        )
    prog = st.progress(0.0, text="1/3 ë‹¨ê³„: ë¶€ë¶„ ìš”ì•½ ì¤‘...")
    for i, ck in enumerate(chunks, start=1):
        sys = "ì•„ë˜ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë…¼ì§€/í‚¤ì›Œë“œ/ìˆ«ìë§Œ 5~7ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½."
        ps = gpt_chat([{"role":"system","content":sys},{"role":"user","content":ck}])
        part_summaries.append(ps); prog.progress(i/len(chunks))
    combined = "\n\n".join(part_summaries)
    reduce_chunks = split_text_by_chars(combined, reduce_chunk_chars)
    reduce_summaries = []
    prog = st.progress(0.0, text="2/3 ë‹¨ê³„: ìš”ì•½ í†µí•© ì¤‘...")
    for i, rc in enumerate(reduce_chunks, start=1):
        sys2 = "ì•„ë˜ ìš”ì•½ë“¤ì„ ì¤‘ë³µ ì œê±°í•˜ê³  í•µì‹¬ë§Œ ì••ì¶•í•´ 4~6ë¬¸ì¥ìœ¼ë¡œ ì¬ìš”ì•½."
        rs = gpt_chat([{"role":"system","content":sys2},{"role":"user","content":rc}])
        reduce_summaries.append(rs); prog.progress(i/len(reduce_chunks))
    final_source = "\n\n".join(reduce_summaries)
    sys3 = f"ì „ì²´ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ, ìˆ«ì/ê³ ìœ ëª…ì‚¬ ìœ ì§€í•˜ë©° ìµœì¢… ìš”ì•½."
    prog = st.progress(0.0, text="3/3 ë‹¨ê³„: ìµœì¢… ìš”ì•½ ì •ë¦¬ ì¤‘...")
    final = gpt_chat([{"role":"system","content":sys3},{"role":"user","content":final_source}])
    prog.progress(1.0); return final

def summarize_content(content: str):
    if not content or not content.strip(): return "ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    n = len(content); target_lines = target_lines_for_length(n)
    st.info(f"ğŸ“ ë¬¸ì„œ ê¸¸ì´: ì•½ {n:,}ì â†’ ëª©í‘œ ìš”ì•½: **{target_lines}ì¤„**")
    if n <= 5000:
        try:
            sys = f"ì•„ë˜ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜."
            return gpt_chat([{"role":"system","content":sys},{"role":"user","content":content}])
        except Exception:
            return summarize_large_text(content, target_lines=target_lines)
    else:
        return summarize_large_text(content, target_lines=target_lines)

# ===== OCR ë³´ì¡° ìœ í‹¸(ê°„ë‹¨ ë¦¬ì‚¬ì´ì¦ˆ) =====
def _prep_im_for_ocr(pil_img: Image.Image, max_side: int = 2000) -> np.ndarray:
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    arr = np.array(pil_img)                         # RGB
    arr = cv2.cvtColor(arr, cv2.COLOR_RGB2BGR)      # BGR
    h, w = arr.shape[:2]
    m = max(h, w)
    if m > max_side:
        scale = max_side / float(m)
        arr = cv2.resize(arr, (int(w*scale), int(h*scale)), interpolation=cv2.INTER_LINEAR)
    return np.ascontiguousarray(arr)

# ======== PDF â†’ í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ (ë‚´ì¥ í…ìŠ¤íŠ¸ ìš°ì„ , OCRì€ í† ê¸€ë¡œ) ========
@st.cache_data(show_spinner=False)
def pdf_pages_to_texts(
    pdf_bytes: bytes,
    *,
    dpi: int = 120,
    min_chars_for_pdftext: int = 10,
    use_ocr: bool = False,   # ê¸°ë³¸ Falseë©´ OCR ì•„ì˜ˆ ì•ˆ í•¨
):
    """
    1) ë‚´ì¥ í…ìŠ¤íŠ¸ ìš°ì„ 
    2) use_ocr=Trueì¼ ë•Œë§Œ ë¶€ì¡±í•œ í˜ì´ì§€ë§Œ ì´ë¯¸ì§€ ë Œë”ë§ + OCR
    return: [(page_no, text), ...], total_pages
    """
    # 1) ë‚´ì¥ í…ìŠ¤íŠ¸
    try:
        reader = PdfReader(io.BytesIO(pdf_bytes))
        base_pages = [(i+1, (p.extract_text() or "")) for i, p in enumerate(reader.pages)]
    except Exception:
        base_pages = []
    total_pages = len(base_pages)

    # ë‚´ì¥ í…ìŠ¤íŠ¸ê°€ ì „í˜€ ì—†ì„ ë•Œ
    if total_pages == 0:
        if not use_ocr:
            return [], 0
        # ì „ì²´ OCR
        try:
            kw = {"dpi": dpi}
            if POPPLER_PATH: kw["poppler_path"] = POPPLER_PATH
            images = convert_from_bytes(pdf_bytes, **kw)
        except PDFInfoNotInstalledError:
            st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: OCR ì‚¬ìš© ë¶ˆê°€")
            return [], 0
        ocr = get_ocr()
        out, prog = [], st.progress(0.0, text=f"OCR ì „ì²´ ì§„í–‰ ì¤‘â€¦ ({len(images)}p, DPI={dpi})")
        for i, img in enumerate(images, start=1):
            arr = _prep_im_for_ocr(img, max_side=2000)
            res = ocr.ocr(arr)
            txt = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            out.append((i, txt))
            prog.progress(i/len(images))
            del img; gc.collect()
        prog.empty()
        return out, len(images)

    # ë‚´ì¥ í…ìŠ¤íŠ¸ê°€ "ìˆì„" ë•Œ
    if not use_ocr:
        # âœ… OCR ë”: ë‚´ì¥ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš© â†’ ê°€ì¥ ë¹ ë¦„
        return base_pages, total_pages

    # OCR ì¼¬: "ì§§ì€" í˜ì´ì§€ë§Œ ë³´ì¶©
    out, prog = [], st.progress(0.0, text=f"ë¶€ì¡± í˜ì´ì§€ë§Œ OCR ë³´ì¶© ì¤‘â€¦ (DPI={dpi})")
    ocr = get_ocr()
    for i, (pg, t) in enumerate(base_pages, start=1):
        s = (t or "").strip()
        if len(s) >= min_chars_for_pdftext:
            out.append((pg, t))
        else:
            try:
                kw = {"dpi": dpi, "first_page": pg, "last_page": pg}
                if POPPLER_PATH: kw["poppler_path"] = POPPLER_PATH
                img = convert_from_bytes(pdf_bytes, **kw)[0]
                arr = _prep_im_for_ocr(img, max_side=2000)
                res = ocr.ocr(arr)
                t2 = "\n".join("".join([w[0] for w in line]) for line in (res[0] or [])) if res else ""
            except PDFInfoNotInstalledError:
                st.warning("âš ï¸ Poppler ë¯¸ì„¤ì¹˜: í•´ë‹¹ í˜ì´ì§€ OCR ê±´ë„ˆëœ€")
                t2 = t or ""
            out.append((pg, t2))
            del img; gc.collect()
        prog.progress(i/total_pages)
    prog.empty()
    return out, total_pages

# ====== UI ìƒíƒœ ======
if "file_key" not in st.session_state:
    st.session_state.file_key = "uploader_1"

st.markdown("<div style='text-align:right'>", unsafe_allow_html=True)
if st.button("ğŸ”„ ì „ì²´ ìƒˆë¡œê³ ì¹¨", key="refresh_all"):
    for k in list(st.session_state.keys()):
        del st.session_state[k]
    st.session_state.file_key = "uploader_" + str(np.random.randint(100000))
    st.rerun()
st.markdown("</div>", unsafe_allow_html=True)

st.title("ğŸ¾ ë”¸ê¹ê³µ Â· PDF ìš”ì•½ (RAG + ì„ íƒ êµ¬ê°„)")

uploaded = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type=["pdf"], key=st.session_state.file_key)
if not uploaded:
    st.info("PDFë¥¼ ì—…ë¡œë“œí•˜ë©´ **í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ í™•ë³´** â†’ (í•„ìš”ì‹œ) **ë²¡í„°DB ì¸ë±ì‹±** â†’ ì›í•˜ëŠ” **í˜ì´ì§€ ë²”ìœ„ë§Œ RAG ìš”ì•½**í•©ë‹ˆë‹¤.")
    st.stop()

pdf_bytes = uploaded.read()


# ====== í˜ì´ì§€ í…ìŠ¤íŠ¸ í™•ë³´(ë‚´ì¥ í…ìŠ¤íŠ¸ ìš°ì„ , í•„ìš”ì‹œë§Œ OCR) ======
with st.spinner("PDF í˜ì´ì§€ í…ìŠ¤íŠ¸ í™•ë³´ ì¤‘â€¦"):
    pages_text, total_pages = pdf_pages_to_texts(
        pdf_bytes,
        dpi=120,                  # ë Œë”ë§ ë¶€ë‹´â†“
        min_chars_for_pdftext=10  # OCR íŠ¸ë¦¬ê±° ìµœì†Œí™”
    )

if total_pages == 0:
    st.error("PDFì—ì„œ í˜ì´ì§€ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

# ====== ì¸ë±ì‹± (ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ) ======
from lib.rag_utils import upsert_doc  # ì¬í™•ì¸
doc_id_guess = _sha1_bytes(pdf_bytes)
if doc_exists(doc_id_guess):
    added, doc_id = 0, doc_id_guess
    st.info(f"âœ… ì´ë¯¸ ì¸ë±ì‹±ë¨: doc_id={doc_id} (ì—…ì„œíŠ¸ ìƒëµ)")
else:
    with st.spinner("ë²¡í„°DB ì¸ë±ì‹± ì¤‘â€¦ (ì¬ì¸ë±ì‹± ë°©ì§€)"):
        added, doc_id = upsert_doc(
            pages_text,
            source_name=uploaded.name,
            file_bytes=pdf_bytes,    # ê°™ì€ íŒŒì¼ì´ë©´ ê°™ì€ doc_id
            chunk_size=800, overlap=200,
            force=False
        )

st.success(f"ğŸ“¦ ì¸ë±ì‹± ìƒíƒœ â€” í˜ì´ì§€ {total_pages} / ì‹ ê·œ ì²­í¬ {added}ê°œ (doc_id: {doc_id})")
st.session_state.current_doc_id = doc_id
st.session_state.total_pages = total_pages

# ====== ì„ íƒ êµ¬ê°„ ìš”ì•½ UI ======
st.subheader("ğŸ“Œ ìš”ì•½ êµ¬ê°„ ì„ íƒ")
page_s, page_e = st.slider("í˜ì´ì§€ ë²”ìœ„", 1, total_pages, (1, min(5, total_pages)))
query = st.text_input("ìš”ì•½ ì£¼ì œ/ì§ˆë¬¸(ì„ íƒ, ê³µë°±ì´ë©´ 'í•µì‹¬ ìš”ì•½')", value="í•µì‹¬ ìš”ì•½")

colA, colB = st.columns([1,1])
with colA:
    if st.button("ğŸ“ ì„ íƒ êµ¬ê°„ë§Œ RAG ìš”ì•½", use_container_width=True):
        with st.spinner("ì„ íƒ êµ¬ê°„ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ë° ìš”ì•½ ì¤‘â€¦"):
            out = rag_summarize_section(
                client=client,
                model=MODEL_SUMMARY,
                doc_id=doc_id,
                query=query or "í•µì‹¬ ìš”ì•½",
                page_range=(page_s, page_e),
                max_chars_context=9000,
                top_k=16
            )
        st.markdown("### âœ… ìš”ì•½ ê²°ê³¼ (ì„ íƒ êµ¬ê°„)")
        st.write(out["summary"])
        with st.expander("ğŸ” ê·¼ê±° ì»¨í…ìŠ¤íŠ¸ ë³´ê¸°"):
            st.code(format_context(out["evidence"]))

with colB:
    if st.button("ğŸ“„ ì „ì²´ ë¬¸ì„œ ì¼ë°˜ ìš”ì•½", use_container_width=True):
        all_text = "\n\n".join([t for _, t in pages_text])
        res = summarize_content(all_text)
        st.markdown("### ğŸ§¾ ì „ì²´ ìš”ì•½ (ì¼ë°˜)")
        st.write(res)

    if st.button("ğŸ§  ì „ì²´ ë¬¸ì„œ RAG ìš”ì•½(ê·¼ê±°)", use_container_width=True):
        with st.spinner("ì „ì²´ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰(RAG) ë° ìš”ì•½ ì¤‘â€¦"):
            out = rag_summarize_section(
                client=client,
                model=MODEL_SUMMARY,
                doc_id=doc_id,
                query=(query or "ì „ì²´ í•µì‹¬ ìš”ì•½"),
                page_range=(1, total_pages),
                max_chars_context=9000,
                top_k=16
            )
        st.markdown("### âœ… ì „ì²´ ë¬¸ì„œ RAG ìš”ì•½ (ê·¼ê±° í¬í•¨)")
        st.write(out["summary"])
        with st.expander("ğŸ” ê·¼ê±° ì»¨í…ìŠ¤íŠ¸ ë³´ê¸°"):
            st.code(format_context(out["evidence"]))
