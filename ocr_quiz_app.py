# -*- coding: utf-8 -*- (ìœ ë‹ˆì½”ë“œë¡œ ìˆ˜ì • 2025/07/25)
import streamlit as st
import numpy as np
import os, re, time, math
import json5
import cv2
from PIL import Image
from openai import OpenAI
from paddleocr import PaddleOCR
from PyPDF2 import PdfReader
from pdf2image import convert_from_bytes
from dotenv import load_dotenv

# ===== âœ… .envì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸° =====
load_dotenv(dotenv_path="C:/Users/user/Desktop/ìµœì¢…íŒŒì¼/AI_final_project/.env")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# ===== í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • =====
st.set_page_config(
    page_title="ğŸ“„ OCR + GPT ìš”ì•½/í€´ì¦ˆ ìƒì„±ê¸°",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ===== ì‚¬ì´ë“œë°” ì™„ì „ ìˆ¨ê¸°ê¸° =====
st.markdown("""
    <style>
    [data-testid="stSidebar"] {display: none !important;}
    .stTextArea textarea { font-size: 0.95rem; line-height: 1.5; }
    </style>
""", unsafe_allow_html=True)

# âœ… file_uploader key ì´ˆê¸°ê°’ ì„¤ì •
if "file_key" not in st.session_state:
    st.session_state.file_key = "uploader_1"

# âœ… ì™„ì „ ìƒˆë¡œê³ ì¹¨
st.markdown("<div style='text-align:right'>", unsafe_allow_html=True)
if st.button("ğŸ”„ ì „ì²´ ìƒˆë¡œê³ ì¹¨", key="refresh_all"):
    keys_to_clear = list(st.session_state.keys())
    for k in keys_to_clear:
        if k in st.session_state:
            del st.session_state[k]
    st.session_state.file_key = "uploader_" + str(np.random.randint(100000))
    st.session_state.quiz_content_input = ""
    st.rerun()
st.markdown("</div>", unsafe_allow_html=True)

# ===== âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ìºì‹± =====
@st.cache_resource
def get_openai_client():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        st.error("âŒ .env íŒŒì¼ì—ì„œ OpenAI API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
    return OpenAI(api_key=api_key)

client = get_openai_client()

# ===== âœ… OCR ìºì‹± =====
@st.cache_resource
def get_ocr():
    return PaddleOCR(
        use_textline_orientation=True,   # ìµœì‹  íŒŒë¼ë¯¸í„°
        lang='korean',
        text_det_box_thresh=0.2,
        text_det_unclip_ratio=2.0,
        ocr_version='PP-OCRv3'
    )
ocr = get_ocr()

# ===== ìœ í‹¸ =====
def extract_pdf_text_if_possible(pdf_file):
    try:
        reader = PdfReader(pdf_file)
        return "\n".join([(page.extract_text() or "") for page in reader.pages])
    except Exception:
        return ""

def safe_load_json5(text):
    try:
        return json5.loads(text)
    except Exception as e:
        st.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        st.code(text)
        return []

# === í† í° ë³´í˜¸ìš© ë¶„í•  ===
def split_text_by_chars(s: str, max_chars: int):
    paras = re.split(r"\n{2,}", s)
    chunks, buff = [], ""
    for p in paras:
        p = p.strip()
        if not p:
            continue
        if len(buff) + len(p) + 2 <= max_chars:
            buff = (buff + "\n\n" + p).strip()
        else:
            if buff:
                chunks.append(buff)
            if len(p) > max_chars:
                sents = re.split(r"(?<=[.!?ã€‚ï¼ï¼Ÿ])\s+", p)
                cur = ""
                for sent in sents:
                    if len(cur) + len(sent) + 1 <= max_chars:
                        cur = (cur + " " + sent).strip()
                    else:
                        if cur:
                            chunks.append(cur)
                        cur = sent
                if cur:
                    chunks.append(cur)
            else:
                buff = p
    if buff:
        chunks.append(buff)
    return chunks

def gpt_chat(messages, model="gpt-4o-mini", temperature=0.2, max_tokens=None):
    try:
        resp = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        msg = str(e)
        if "rate_limit_exceeded" in msg or "Request too large" in msg:
            time.sleep(1.2)
        raise

# === ìš”ì•½ ê¸¸ì´ ìë™ ê²°ì •(ë¬¸ì„œ ê¸¸ì´ â†’ ëª©í‘œ ì¤„ ìˆ˜) ===
def target_lines_for_length(n_chars: int) -> int:
    """
    ë¬¸ì„œ ê¸¸ì´ì— ë”°ë¼ ëª©í‘œ ìš”ì•½ ì¤„ ìˆ˜ë¥¼ ìë™ ê²°ì •.
    í•„ìš”í•˜ë©´ êµ¬ê°„/ê°’ ì¡°ì • ê°€ëŠ¥.
    """
    if n_chars < 1500:       # ì•„ì£¼ ì§§ìŒ
        return 4
    elif n_chars < 5000:     # ì§§ìŒ
        return 6
    elif n_chars < 12000:    # ë³´í†µ
        return 8
    elif n_chars < 25000:    # ê¹€
        return 10
    elif n_chars < 50000:    # ë§¤ìš° ê¹€
        return 13
    else:                    # ì´ˆì¥ë¬¸
        return 16

# === ëŒ€ìš©ëŸ‰ ì•ˆì „ ìš”ì•½ ===
def summarize_large_text(text, target_lines=8, base_chunk_chars=7000, reduce_chunk_chars=4000):
    """
    1) ë³¸ë¬¸ì„ chunk ìš”ì•½
    2) ë¶€ë¶„ ìš”ì•½ë“¤ì„ ë‹¤ì‹œ chunk ìš”ì•½
    3) ìµœì¢… ìš”ì•½ìœ¼ë¡œ ì¶•ì•½
    target_lines: ìµœì¢… ìš”ì•½ ëª©í‘œ ì¤„ ìˆ˜(ìë™ ê²°ì •ê°’ ì‚¬ìš©)
    """
    if not text or len(text.strip()) == 0:
        return ""

    chunks = split_text_by_chars(text, base_chunk_chars)
    part_summaries = []

    if len(chunks) == 1:
        sys = f"ì•„ë˜ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜."
        return gpt_chat(
            [{"role": "system", "content": sys},
             {"role": "user", "content": chunks[0]}]
        )

    prog = st.progress(0.0, text="1/3 ë‹¨ê³„: ë¶€ë¶„ ìš”ì•½ ì¤‘...")
    for i, ck in enumerate(chunks, start=1):
        sys = "ì•„ë˜ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë…¼ì§€/í‚¤ì›Œë“œ/ìˆ«ìë§Œ 5~7ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½."
        try:
            ps = gpt_chat(
                [{"role": "system", "content": sys},
                 {"role": "user", "content": ck}]
            )
        except Exception:
            smaller = split_text_by_chars(ck, max(2000, base_chunk_chars // 2))
            local_sum = []
            for sck in smaller:
                ls = gpt_chat(
                    [{"role": "system", "content": sys},
                     {"role": "user", "content": sck}]
                )
                local_sum.append(ls)
            ps = "\n".join(local_sum)
        part_summaries.append(ps)
        prog.progress(i / len(chunks))

    combined = "\n\n".join(part_summaries)
    reduce_chunks = split_text_by_chars(combined, reduce_chunk_chars)
    reduce_summaries = []

    prog = st.progress(0.0, text="2/3 ë‹¨ê³„: ìš”ì•½ í†µí•© ì¤‘...")
    for i, rc in enumerate(reduce_chunks, start=1):
        sys2 = "ì•„ë˜ ìš”ì•½ë“¤ì„ ì¤‘ë³µ ì œê±°í•˜ê³  í•µì‹¬ë§Œ ì••ì¶•í•´ 4~6ë¬¸ì¥ìœ¼ë¡œ ì¬ìš”ì•½."
        rs = gpt_chat(
            [{"role": "system", "content": sys2},
             {"role": "user", "content": rc}]
        )
        reduce_summaries.append(rs)
        prog.progress(i / len(reduce_chunks))

    final_source = "\n\n".join(reduce_summaries)
    sys3 = f"ì „ì²´ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ, ìˆ«ì/ê³ ìœ ëª…ì‚¬ ìœ ì§€í•˜ë©° ìµœì¢… ìš”ì•½."
    prog = st.progress(0.0, text="3/3 ë‹¨ê³„: ìµœì¢… ìš”ì•½ ì •ë¦¬ ì¤‘...")
    final = gpt_chat(
        [{"role": "system", "content": sys3},
         {"role": "user", "content": final_source}]
    )
    prog.progress(1.0)
    return final

def summarize_content(content: str):
    """ë¬¸ì„œ ê¸¸ì´ë¥¼ ë³´ê³  ëª©í‘œ ì¤„ ìˆ˜ë¥¼ ìë™ ê²°ì •í•´ ìš”ì•½."""
    if not content or not content.strip():
        return "ìš”ì•½í•  ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."
    n = len(content)
    target_lines = target_lines_for_length(n)

    # ì‚¬ìš©ìê°€ ë³´ì´ë„ë¡ ì„ íƒëœ ëª©í‘œ ì¤„ ìˆ˜ ì•ˆë‚´(ì„ íƒ)
    st.info(f"ğŸ“ ë¬¸ì„œ ê¸¸ì´: ì•½ {n:,}ì â†’ ëª©í‘œ ìš”ì•½: **{target_lines}ì¤„**")

    if n <= 5000:
        try:
            sys = f"ì•„ë˜ ë‚´ìš©ì„ {max(2, target_lines-1)}~{target_lines+1}ì¤„ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜."
            return gpt_chat(
                [{"role": "system", "content": sys},
                 {"role": "user", "content": content}]
            )
        except Exception:
            return summarize_large_text(content, target_lines=target_lines)
    else:
        return summarize_large_text(content, target_lines=target_lines)

# === í€´ì¦ˆ ìƒì„± ì „ ì…ë ¥ ì¶•ì•½ ===
def compact_for_quiz_if_needed(text, max_chars=6000):
    if len(text) <= max_chars:
        return text
    sys = "ì•„ë˜ í•™ìŠµ ë‚´ìš©ì„ í€´ì¦ˆ ìƒì„±ì— í•„ìš”í•œ í•µì‹¬ ê°œë…/ì •ì˜/ìˆ˜ì¹˜/ê´€ê³„ ìœ„ì£¼ë¡œ 800~1200ìë¡œ ì••ì¶•í•´ì¤˜."
    return gpt_chat(
        [{"role": "system", "content": sys},
         {"role": "user", "content": text}]
    )

def generate_quiz(content, quiz_count=8):
    content = compact_for_quiz_if_needed(content, max_chars=6000)

    prompt = f"""
ë„ˆëŠ” ë˜‘ë˜‘í•œ êµìœ¡ìš© ì„ ìƒë‹˜ì´ì•¼. ì•„ë˜ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì–‘í•œ ìœ í˜•ì˜ í€´ì¦ˆë¥¼ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì¤˜.

ì˜ˆì‹œ:
[
  {{
    "type": "ê°ê´€ì‹",
    "question": "ì˜ˆì‹œ ì§ˆë¬¸",
    "options": ["A", "B", "C", "D"],
    "answer": "A",
    "explanation": "ì •ë‹µ í•´ì„¤",
    "example": "ê´€ë ¨ ë°°ê²½ ì„¤ëª…"
  }}
]

- ë°˜ë“œì‹œ 'type', 'question', 'answer', 'explanation', 'example' í‚¤ í¬í•¨
- 'options'ëŠ” ê°ê´€ì‹, OXì—ë§Œ í¬í•¨ (ì£¼ê´€ì‹/ë¹ˆì¹¸í˜• ì œì™¸)
- JSON ë¦¬ìŠ¤íŠ¸ë§Œ ì¶œë ¥ (ì„¤ëª…ë¬¸ ê¸ˆì§€)
- ì´ {quiz_count}ë¬¸ì œ
"""
    try:
        raw = gpt_chat(
            [{"role": "system", "content": prompt},
             {"role": "user", "content": content}],
            model="gpt-4o-mini"
        )
        if raw.startswith("```"):
            raw = raw.strip("`")
            raw = re.sub(r"^json", "", raw, flags=re.IGNORECASE).strip()
        parsed = safe_load_json5(raw)
        return parsed[:quiz_count] if isinstance(parsed, list) else []
    except Exception as e:
        st.error(f"âŒ í€´ì¦ˆ ìƒì„± ì‹¤íŒ¨: {e}")
        return []

def ask_gpt_about_wrong(problem, user_answer):
    prompt = f"""ë¬¸ì œ: {problem.get('question','')}
ì •ë‹µ: {problem.get('answer','')}
ë‚´ê°€ ì‘ì„±í•œ ì˜¤ë‹µ: {user_answer}
ì™œ í‹€ë ¸ëŠ”ì§€ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜."""
    return gpt_chat(
        [{"role": "system", "content": "ë„ˆëŠ” ì¹œì ˆí•œ ì„ ìƒë‹˜ì´ì•¼."},
         {"role": "user", "content": prompt}]
    )

def summarize_answer(answer):
    try:
        sys = "ì•„ë˜ ë‚´ìš©ì„ ìµœëŒ€ 2ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ë§Œ ìš”ì•½í•´ì¤˜."
        return gpt_chat(
            [{"role": "system", "content": sys},
             {"role": "user", "content": answer}]
        )
    except:
        return "ìš”ì•½ ì‹¤íŒ¨"

# ===== íƒ­ êµ¬ì„± =====
tab1, tab2 = st.tabs(["ğŸ“„ PDFìš”ì•½ê¸°", "ğŸ§  í€´ì¦ˆ ìƒì„±ê¸°"])

with tab1:
    st.header("ğŸ“„ PDF ìš”ì•½")
    uploaded_file = st.file_uploader(
        "ğŸ“¤ PDF ë˜ëŠ” ì´ë¯¸ì§€ ì—…ë¡œë“œ",
        type=["png", "jpg", "jpeg", "pdf"],
        key=st.session_state.file_key
    )

    clean_text = ""
    if uploaded_file:
        is_pdf = (uploaded_file.type == "application/pdf")
        pdf_has_no_text = False

        if is_pdf:
            # 1) í…ìŠ¤íŠ¸ ë ˆì´ì–´ ì¶”ì¶œ
            text = extract_pdf_text_if_possible(uploaded_file)
            if text.strip():
                clean_text = text
                st.success("âœ… PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
            else:
                # 2) ìŠ¤ìº” PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ í›„ OCR
                st.warning("ğŸ” í…ìŠ¤íŠ¸ ë ˆì´ì–´ê°€ ì—†ì–´ ë³´ì…ë‹ˆë‹¤. OCRë¡œ ì¸ì‹í•©ë‹ˆë‹¤.")
                if convert_from_bytes is None:
                    st.error("pdf2image / popplerê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
                else:
                    images = convert_from_bytes(uploaded_file.read(), dpi=200, fmt='png')
                    ocr_texts = []
                    with st.spinner("OCR ì¸ì‹ ì¤‘..."):
                        for i, pil_img in enumerate(images, 1):
                            img_np = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                            result = ocr.ocr(img_np, cls=False)
                            lines = []
                            for det in result:
                                for box, txt in det:
                                    lines.append(txt[0])
                            ocr_texts.append("\n".join(lines))
                            st.write(f"í˜ì´ì§€ {i} OCR ì™„ë£Œ")
                    clean_text = "\n\n".join(ocr_texts).strip()
                    if clean_text:
                        st.success("âœ… OCR ì¸ì‹ ì™„ë£Œ")
                    else:
                        pdf_has_no_text = True
                        st.error("âŒ OCRë¡œë„ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            # ì´ë¯¸ì§€ íŒŒì¼ OCR
            img = Image.open(uploaded_file).convert("RGB")
            st.image(img, caption="ğŸ–¼ï¸ ì—…ë¡œë“œëœ ì´ë¯¸ì§€", width=600)
            img_np = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            with st.spinner("OCR ì¸ì‹ ì¤‘..."):
                result = ocr.ocr(img_np, cls=False)
                lines = []
                for det in result:
                    for box, txt in det:
                        lines.append(txt[0])
                clean_text = "\n".join(lines).strip()
            if clean_text:
                st.success("âœ… OCR ì¸ì‹ ì™„ë£Œ")
            else:
                st.error("âŒ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        if not pdf_has_no_text and clean_text.strip():
            st.text_area("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸", clean_text, height=250, key="ocr_result_text")
            if st.button("ğŸ“š GPT ìš”ì•½í•˜ê¸°"):
                with st.spinner("ìš”ì•½ ì¤‘... (ë¬¸ì„œ ê¸¸ì´ ê¸°ë°˜ ìë™ ìš”ì•½ ê¸¸ì´ ì„¤ì •)"):
                    summary = summarize_content(clean_text)  # â† ìë™ ê¸¸ì´ ê²°ì •
                    st.session_state.summary = summary
                    st.text_area("ğŸ“Œ ìš”ì•½ ê²°ê³¼", summary, height=180, key="summary_text")

with tab2:
    st.header("ğŸ§  í€´ì¦ˆìƒì„±ê¸°")

    quiz_count = st.number_input(
        "í€´ì¦ˆ ë¬¸ì œ ì¶œì œ ìˆ˜ëŠ” 4ê°œ~10ê°œ ì‚¬ì´ë¡œ ì‚¬ìš©í•˜ì„¸ìš”!",
        min_value=4, max_value=10, value=8, step=1
    )
    content_input = st.text_area(
        "âœï¸ í•™ìŠµ ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ PDF ìš”ì•½ ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”",
        value=st.session_state.get("quiz_content_input", ""),
        height=200,
        key="quiz_content_input"
    )
    st.markdown("âœ… PDF ìš”ì•½ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ìë™ìœ¼ë¡œ ê·¸ ë‚´ìš©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    if st.button("ğŸ§  í€´ì¦ˆ ìƒì„±í•˜ê¸°", key="make_quiz"):
        content_to_use = (st.session_state.get("summary", "") or content_input).strip()
        if not content_to_use:
            st.warning("ë‚´ìš©ì„ ì…ë ¥í•˜ê±°ë‚˜ ìš”ì•½ ê²°ê³¼ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        elif len(content_to_use) < 5:
            st.error("âŒ í€´ì¦ˆë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        else:
            with st.spinner("GPTê°€ í€´ì¦ˆë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... (ì¥ë¬¸ ìë™ ì••ì¶•)"):
                st.session_state.summary_log = summarize_content(content_to_use[:20000])
                st.session_state.quiz_data = generate_quiz(content_to_use, quiz_count)
                st.session_state.user_answers = {}
                st.session_state.wrong_indices = []
                st.session_state.chat_logs = {}
                st.session_state.graded = False

    if st.session_state.get("summary_log"):
        st.info(f"ğŸ“š í•™ìŠµ ìš”ì•½:\n\n{st.session_state.summary_log}")

    # ===== ì…ë ¥ UI =====
    def render_quiz_inputs():
        for idx, quiz in enumerate(st.session_state.quiz_data):
            st.markdown(f"### ë¬¸ì œ {idx + 1} ({quiz.get('type','-')})")
            st.markdown(f"**{quiz.get('question','-')}**")

            qtype = (quiz.get("type") or "").strip()
            key_input = f"input_{idx}"

            if qtype in ["ê°ê´€ì‹", "OX"]:
                options = quiz.get("options", [])
                if qtype == "OX" and not options:
                    options = ["O", "X"]
                st.session_state.user_answers[idx] = st.selectbox(
                    "ì •ë‹µ ì„ íƒ",
                    options,
                    index=None,
                    placeholder="ì„ íƒ",
                    key=key_input
                )
            else:
                st.session_state.user_answers[idx] = st.text_input("ì •ë‹µ ì…ë ¥", key=key_input)

    # ===== ì±„ì  =====
    def normalize(s):
        if isinstance(s, (list, tuple)):
            return [str(x).strip().lower() for x in s]
        return str(s).strip().lower()

    def is_correct(user, answer):
        u = normalize(user)
        a = normalize(answer)
        if isinstance(a, list):
            return u in a
        return u == a

    if st.session_state.get("quiz_data"):
        render_quiz_inputs()

        if st.button("âœ… ì „ì²´ ì±„ì ", key="grade_all"):
            unanswered = [i for i in range(len(st.session_state.quiz_data))
                          if st.session_state.user_answers.get(i, None) in [None, ""]]
            if unanswered:
                st.warning(f"ì•„ì§ ë‹µì„ ì„ íƒ/ì…ë ¥í•˜ì§€ ì•Šì€ ë¬¸ì œê°€ ìˆì–´ìš”: {', '.join(str(i+1) for i in unanswered)}")
            else:
                st.session_state.wrong_indices = []
                for i, quiz in enumerate(st.session_state.quiz_data):
                    user = st.session_state.user_answers.get(i, "")
                    answer = quiz.get("answer", "")
                    correct = is_correct(user, answer)

                    st.markdown(f"**ë¬¸ì œ {i + 1}: {'âœ… ì •ë‹µ' if correct else 'âŒ ì˜¤ë‹µ'}**")
                    st.markdown(f"- ì§ˆë¬¸: {quiz.get('question', '-')}")
                    if quiz.get("type") in ["ê°ê´€ì‹", "OX"]:
                        st.markdown(f"- ì„ íƒì§€: {', '.join(quiz.get('options', []))}")
                    st.markdown(f"- ë‚´ ë‹µ: {user}")
                    st.markdown(f"- ì •ë‹µ: {answer}")
                    st.markdown(f"- í•´ì„¤: {quiz.get('explanation', 'ì—†ìŒ')}")
                    st.markdown(f"- ì˜ˆì‹œ: {quiz.get('example', 'ì—†ìŒ')}")
                    st.markdown("---")

                    if not correct:
                        st.session_state.wrong_indices.append(i)

                st.session_state.graded = True

    # ===== ì˜¤ë‹µë§Œ GPTì—ê²Œ ì§ˆë¬¸ =====
    if st.session_state.get("graded") and st.session_state.get("wrong_indices"):
        for i in st.session_state.wrong_indices:
            quiz = st.session_state.quiz_data[i]
            user_answer = st.session_state.user_answers[i]
            question_key = quiz.get("question", str(i))

            if question_key not in st.session_state.chat_logs:
                reply = ask_gpt_about_wrong(quiz, user_answer)
                st.session_state.chat_logs[question_key] = [{"role": "assistant", "content": reply}]
                st.session_state[f"last_reply_{i}"] = reply

            with st.expander(f"ğŸ’¬ GPTì—ê²Œ ë¬¸ì œ {i+1} ì§ˆë¬¸í•˜ê¸°", expanded=True):
                st.markdown(f"ğŸ§  GPT ë‹µë³€: {st.session_state[f'last_reply_{i}']}")
                st.markdown(f"ğŸ“Œ ìš”ì•½: {summarize_answer(st.session_state[f'last_reply_{i}'])}")

                with st.form(key=f"form_followup_{i}"):
                    key_followup = f"followup_{i}_text"
                    user_followup = st.text_input("ì¶”ê°€ ì§ˆë¬¸ ì…ë ¥", key=key_followup)
                    submitted = st.form_submit_button("ì§ˆë¬¸ ë³´ë‚´ê¸°")
                    if submitted and user_followup.strip():
                        chat = st.session_state.chat_logs[question_key]
                        chat.append({"role": "user", "content": user_followup})
                        reply = gpt_chat(
                            [{"role": "system", "content": "ì¹œì ˆí•œ í”¼ë“œë°±ì„ ì œê³µí•´ì¤˜."}] + chat
                        )
                        chat.append({"role": "assistant", "content": reply})
                        st.session_state.chat_logs[question_key] = chat
                        st.session_state[f"last_reply_{i}"] = reply
